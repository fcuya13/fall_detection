{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-24T20:31:36.631024Z",
     "start_time": "2025-05-24T20:31:36.553324Z"
    }
   },
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import re\n",
    "from PIL import Image\n",
    "from collections import defaultdict"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# CAUCAFALL",
   "id": "1378afd153dcd7a2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T20:45:12.566050Z",
     "start_time": "2025-05-24T20:44:19.713944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Paths\n",
    "img_dir = 'dataset/CAUCAFall/all_imgs'\n",
    "label_dir = 'dataset/CAUCAFall/all_labels'\n",
    "\n",
    "# Output directories\n",
    "output_base = 'dataset/CAUCAFall/CAUCAFall_split_subjects_v2'\n",
    "splits = ['train', 'valid', 'test']\n",
    "\n",
    "# Crear carpetas de salida\n",
    "for split in splits:\n",
    "    os.makedirs(os.path.join(output_base, split, 'images'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_base, split, 'labels'), exist_ok=True)\n",
    "\n",
    "# Expresión regular para extraer SUBJECT del nombre\n",
    "pattern = re.compile(r'.*?(\\d{1,2})[-]?\\d{5}\\.(jpg|png)$', re.IGNORECASE)\n",
    "\n",
    "# Agrupar imágenes por SUBJECT\n",
    "subject_to_files = {}\n",
    "\n",
    "for filename in os.listdir(img_dir):\n",
    "    match = pattern.match(filename)\n",
    "    if match:\n",
    "        subject = int(match.group(1))\n",
    "        subject_to_files.setdefault(subject, []).append(filename)\n",
    "\n",
    "# Verifica que haya exactamente 10 SUBJECTS\n",
    "subjects = sorted(subject_to_files.keys())\n",
    "if len(subjects) != 10:\n",
    "    raise ValueError(f\"Se esperaban 10 SUBJECTS, pero se encontraron {len(subjects)}: {subjects}\")\n",
    "\n",
    "# Mezclar aleatoriamente los SUBJECTS\n",
    "#random.seed(42)\n",
    "#random.shuffle(subjects)\n",
    "train_subjects = subjects[:7]\n",
    "valid_subjects = subjects[7:9]\n",
    "test_subject = subjects[9]\n",
    "\n",
    "split_map = {subj: 'train' for subj in train_subjects}\n",
    "split_map.update({subj: 'valid' for subj in valid_subjects})\n",
    "split_map[test_subject] = 'test'\n",
    "\n",
    "# Mover archivos\n",
    "for subject, files in subject_to_files.items():\n",
    "    split = split_map[subject]\n",
    "    for img_file in files:\n",
    "        label_file = os.path.splitext(img_file)[0] + '.txt'\n",
    "\n",
    "        src_img = os.path.join(img_dir, img_file)\n",
    "        src_lbl = os.path.join(label_dir, label_file)\n",
    "\n",
    "        dst_img = os.path.join(output_base, split, 'images', img_file)\n",
    "        dst_lbl = os.path.join(output_base, split, 'labels', label_file)\n",
    "\n",
    "        shutil.copy2(src_img, dst_img)\n",
    "        if os.path.exists(src_lbl):\n",
    "            shutil.copy2(src_lbl, dst_lbl)\n",
    "        else:\n",
    "            print(f\"[ADVERTENCIA] No se encontró etiqueta para {img_file}\")\n",
    "\n",
    "print(\"✅ División completada.\")\n",
    "print(f\"Train SUBJECTS: {train_subjects}\")\n",
    "print(f\"Valid SUBJECT: {valid_subjects}\")"
   ],
   "id": "d5702bac11fffc14",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ División completada.\n",
      "Train SUBJECTS: [1, 2, 3, 4, 5, 6, 7]\n",
      "Valid SUBJECT: [8, 9]\n",
      "Test SUBJECT: 10\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T20:51:39.746848Z",
     "start_time": "2025-05-24T20:51:00.092994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Directorio base\n",
    "base_dir = output_base\n",
    "splits = ['train', 'valid', 'test']\n",
    "class_names = {0: 'ADL', 1: 'FALL'}\n",
    "\n",
    "# Inicializar contadores\n",
    "distribution = {split: {0: 0, 1: 0} for split in splits}\n",
    "\n",
    "for split in splits:\n",
    "    label_path = os.path.join(base_dir, split, 'labels')\n",
    "    for filename in os.listdir(label_path):\n",
    "        if not filename.endswith('.txt'):\n",
    "            continue\n",
    "        with open(os.path.join(label_path, filename), 'r') as f:\n",
    "            for line in f:\n",
    "                class_id = int(line.strip().split()[0])\n",
    "                if class_id in [0, 1]:\n",
    "                    distribution[split][class_id] += 1\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"📊 Distribución de clases:\")\n",
    "for split in splits:\n",
    "    print(f\"\\n{split.upper()}:\")\n",
    "    for class_id, count in distribution[split].items():\n",
    "        print(f\"  {class_names[class_id]} (clase {class_id}): {count}\")"
   ],
   "id": "6f4a714c0a3d6d7e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Distribución de clases:\n",
      "\n",
      "TRAIN:\n",
      "  ADL (clase 0): 9101\n",
      "  FALL (clase 1): 8284\n",
      "\n",
      "VALID:\n",
      "  ADL (clase 0): 2911\n",
      "  FALL (clase 1): 1353\n",
      "\n",
      "TEST:\n",
      "  ADL (clase 0): 1595\n",
      "  FALL (clase 1): 893\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T20:50:35.454634Z",
     "start_time": "2025-05-24T20:49:03.596157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Directorio base del dataset\n",
    "base_dir = output_base\n",
    "#splits_v1 = ['train', 'valid', 'test']\n",
    "splits = ['train']\n",
    "class_names = {0: 'ADL', 1: 'FALL'}\n",
    "\n",
    "def count_labels(label_file):\n",
    "    with open(label_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    fall = sum(1 for l in lines if l.startswith('1 '))\n",
    "    adl = sum(1 for l in lines if l.startswith('0 '))\n",
    "    return adl, fall\n",
    "\n",
    "for split in splits:\n",
    "    img_dir = os.path.join(base_dir, split, 'images')\n",
    "    lbl_dir = os.path.join(base_dir, split, 'labels')\n",
    "\n",
    "    adl_files = []\n",
    "    fall_files = []\n",
    "\n",
    "    for label_file in os.listdir(lbl_dir):\n",
    "        if not label_file.endswith('.txt'):\n",
    "            continue\n",
    "        full_path = os.path.join(lbl_dir, label_file)\n",
    "        adl_count, fall_count = count_labels(full_path)\n",
    "\n",
    "        base_name = os.path.splitext(label_file)[0]\n",
    "        if fall_count > 0:\n",
    "            fall_files.append(base_name)\n",
    "        elif adl_count > 0:\n",
    "            adl_files.append(base_name)\n",
    "\n",
    "    print(f\"\\n📂 {split.upper()} - FALL: {len(fall_files)}, ADL: {len(adl_files)}\")\n",
    "\n",
    "    # 1. REFLEJAR FALL\n",
    "    for base_name in fall_files:\n",
    "        img_path = os.path.join(img_dir, base_name + '.jpg')\n",
    "        label_path = os.path.join(lbl_dir, base_name + '.txt')\n",
    "\n",
    "        if not os.path.exists(img_path):\n",
    "            img_path = os.path.join(img_dir, base_name + '.png')\n",
    "            if not os.path.exists(img_path):\n",
    "                continue\n",
    "\n",
    "        # Reflejar imagen horizontalmente\n",
    "        img = Image.open(img_path)\n",
    "        flipped_img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        if flipped_img.mode == 'RGBA':\n",
    "            flipped_img = flipped_img.convert('RGB')\n",
    "        # Guardar imagen reflejada\n",
    "        new_img_name = base_name + '_flip.jpg'\n",
    "        flipped_img.save(os.path.join(img_dir, new_img_name))\n",
    "\n",
    "        # Reflejar label\n",
    "        with open(label_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        new_lines = []\n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            cls, x_center, y_center, width, height = parts\n",
    "            x_center = str(1.0 - float(x_center))  # invertir horizontalmente\n",
    "            new_lines.append(f\"{cls} {x_center} {y_center} {width} {height}\\n\")\n",
    "\n",
    "        with open(os.path.join(lbl_dir, base_name + '_flip.txt'), 'w') as f:\n",
    "            f.writelines(new_lines)\n",
    "\n",
    "    # 2. DUPLICAR ADL HASTA BALANCEAR\n",
    "    new_fall_total = len(fall_files) * 2\n",
    "    adl_needed = new_fall_total - len(adl_files)\n",
    "    print(f\"🔁 Se necesitan {adl_needed} duplicaciones de ADL para balancear\")\n",
    "\n",
    "    if adl_needed > 0:\n",
    "        sampled = random.choices(adl_files, k=adl_needed)\n",
    "        for i, base_name in enumerate(sampled):\n",
    "            src_img_path = os.path.join(img_dir, base_name + '.jpg')\n",
    "            if not os.path.exists(src_img_path):\n",
    "                src_img_path = os.path.join(img_dir, base_name + '.png')\n",
    "                if not os.path.exists(src_img_path):\n",
    "                    continue\n",
    "\n",
    "            src_lbl_path = os.path.join(lbl_dir, base_name + '.txt')\n",
    "            if not os.path.exists(src_lbl_path):\n",
    "                continue\n",
    "\n",
    "            # Reflejar imagen\n",
    "            img = Image.open(src_img_path)\n",
    "            flipped_img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            if flipped_img.mode == 'RGBA':\n",
    "                flipped_img = flipped_img.convert('RGB')\n",
    "            new_base = f\"{base_name}_flipdup{i}\"\n",
    "            flipped_img.save(os.path.join(img_dir, new_base + '.jpg'))\n",
    "\n",
    "            # Reflejar label\n",
    "            with open(src_lbl_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "\n",
    "            new_lines = []\n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                cls, x_center, y_center, width, height = parts\n",
    "                x_center = str(1.0 - float(x_center))\n",
    "                new_lines.append(f\"{cls} {x_center} {y_center} {width} {height}\\n\")\n",
    "\n",
    "            with open(os.path.join(lbl_dir, new_base + '.txt'), 'w') as f:\n",
    "                f.writelines(new_lines)\n",
    "\n",
    "print(\"\\n✅ Dataset balanceado con reflejo de FALL y duplicación de ADL.\")"
   ],
   "id": "7313f0a672a69d7b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📂 TRAIN - FALL: 4142, ADL: 9101\n",
      "🔁 Se necesitan -817 duplicaciones de ADL para balancear\n",
      "\n",
      "✅ Dataset balanceado con reflejo de FALL y duplicación de ADL.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# MULTIPLE CAM",
   "id": "238a5ad6efacb6b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T21:02:44.394343Z",
     "start_time": "2025-05-24T21:02:14.711759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Rutas\n",
    "base_dir = \"dataset/Multiple_Cameras\"\n",
    "img_dir = os.path.join(base_dir, \"all_imgs\")\n",
    "label_dir = os.path.join(base_dir, \"all_labels\")\n",
    "\n",
    "# Carpeta de salida\n",
    "output_dir = os.path.join(base_dir, \"Multiple_Camera_split_chutes_v2\")\n",
    "splits = ['train', 'valid', 'test']\n",
    "for split in splits:\n",
    "    os.makedirs(os.path.join(output_dir, split, 'images'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, split, 'labels'), exist_ok=True)\n",
    "\n",
    "# Agrupar archivos por chute\n",
    "chute_dict = defaultdict(list)\n",
    "\n",
    "for filename in os.listdir(img_dir):\n",
    "    if not (filename.endswith(\".jpg\") or filename.endswith(\".png\")):\n",
    "        continue\n",
    "    chute_id = filename.split(\"_\")[0]\n",
    "    base_name = os.path.splitext(filename)[0]\n",
    "    chute_dict[chute_id].append(base_name)\n",
    "\n",
    "# Obtener lista única de chutes\n",
    "all_chutes = list(chute_dict.keys())\n",
    "all_chutes.sort()\n",
    "random.seed(42)\n",
    "random.shuffle(all_chutes)\n",
    "\n",
    "# Dividir chutes\n",
    "train_chutes = all_chutes[:15]\n",
    "valid_chutes = all_chutes[15:19]\n",
    "test_chutes = all_chutes[19:24]\n",
    "\n",
    "split_map = {\n",
    "    'train': train_chutes,\n",
    "    'valid': valid_chutes,\n",
    "    'test': test_chutes\n",
    "}\n",
    "\n",
    "# Copiar archivos según el split asignado\n",
    "for split, chutes in split_map.items():\n",
    "    for chute in chutes:\n",
    "        for base_name in chute_dict[chute]:\n",
    "            img_src = os.path.join(img_dir, base_name + \".jpg\")\n",
    "            if not os.path.exists(img_src):  # prueba con png si no existe jpg\n",
    "                img_src = os.path.join(img_dir, base_name + \".png\")\n",
    "                if not os.path.exists(img_src):\n",
    "                    continue\n",
    "            label_src = os.path.join(label_dir, base_name + \".txt\")\n",
    "            if not os.path.exists(label_src):\n",
    "                continue\n",
    "\n",
    "            img_dst = os.path.join(output_dir, split, 'images', os.path.basename(img_src))\n",
    "            label_dst = os.path.join(output_dir, split, 'labels', os.path.basename(label_src))\n",
    "\n",
    "            shutil.copy2(img_src, img_dst)\n",
    "            shutil.copy2(label_src, label_dst)\n",
    "\n",
    "print(\"✅ Dataset separado por CHUTE en train (16), valid (4) y test (4)\")"
   ],
   "id": "2b7572f4bd4789bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset separado por CHUTE en train (16), valid (4) y test (4)\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T21:02:59.097383Z",
     "start_time": "2025-05-24T21:02:59.090202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"TRAIN\")\n",
    "print(train_chutes)\n",
    "print(\"VALID\")\n",
    "print(valid_chutes)\n",
    "print(\"TEST\")\n",
    "print(test_chutes)"
   ],
   "id": "bfea5b8a2c558f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "['17', '16', '03', '15', '06', '14', '18', '13', '23', '07', '10', '02', '20', '12', '11']\n",
      "VALID\n",
      "['22', '05', '19', '08']\n",
      "TEST\n",
      "['09', '01', '04', '21']\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T21:08:00.972209Z",
     "start_time": "2025-05-24T21:07:38.931315Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Directorio base\n",
    "base_dir = \"dataset/Multiple_Cameras/Multiple_Camera_split_chutes_v2\"\n",
    "splits = ['train', 'valid', 'test']\n",
    "class_names = {0: 'ADL', 1: 'FALL'}\n",
    "\n",
    "# Inicializar contadores\n",
    "distribution = {split: {0: 0, 1: 0} for split in splits}\n",
    "\n",
    "for split in splits:\n",
    "    label_path = os.path.join(base_dir, split, 'labels')\n",
    "    for filename in os.listdir(label_path):\n",
    "        if not filename.endswith('.txt'):\n",
    "            continue\n",
    "        with open(os.path.join(label_path, filename), 'r') as f:\n",
    "            for line in f:\n",
    "                class_id = int(line.strip().split()[0])\n",
    "                if class_id in [0, 1]:\n",
    "                    distribution[split][class_id] += 1\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"📊 Distribución de clases:\")\n",
    "for split in splits:\n",
    "    print(f\"\\n{split.upper()}:\")\n",
    "    for class_id, count in distribution[split].items():\n",
    "        print(f\"  {class_names[class_id]} (clase {class_id}): {count}\")"
   ],
   "id": "4037fbd852cb215b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Distribución de clases:\n",
      "\n",
      "TRAIN:\n",
      "  ADL (clase 0): 6866\n",
      "  FALL (clase 1): 6866\n",
      "\n",
      "VALID:\n",
      "  ADL (clase 0): 779\n",
      "  FALL (clase 1): 784\n",
      "\n",
      "TEST:\n",
      "  ADL (clase 0): 737\n",
      "  FALL (clase 1): 471\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T21:07:29.784277Z",
     "start_time": "2025-05-24T21:05:44.832974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Directorio base del dataset\n",
    "base_dir = \"dataset/Multiple_Cameras/Multiple_Camera_split_chutes_v2\"\n",
    "#splits_v1 = ['train', 'valid', 'test']\n",
    "splits = ['train']\n",
    "class_names = {0: 'ADL', 1: 'FALL'}\n",
    "\n",
    "def count_labels(label_file):\n",
    "    with open(label_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    fall = sum(1 for l in lines if l.startswith('1 '))\n",
    "    adl = sum(1 for l in lines if l.startswith('0 '))\n",
    "    return adl, fall\n",
    "\n",
    "for split in splits:\n",
    "    img_dir = os.path.join(base_dir, split, 'images')\n",
    "    lbl_dir = os.path.join(base_dir, split, 'labels')\n",
    "\n",
    "    adl_files = []\n",
    "    fall_files = []\n",
    "\n",
    "    for label_file in os.listdir(lbl_dir):\n",
    "        if not label_file.endswith('.txt'):\n",
    "            continue\n",
    "        full_path = os.path.join(lbl_dir, label_file)\n",
    "        adl_count, fall_count = count_labels(full_path)\n",
    "\n",
    "        base_name = os.path.splitext(label_file)[0]\n",
    "        if fall_count > 0:\n",
    "            fall_files.append(base_name)\n",
    "        elif adl_count > 0:\n",
    "            adl_files.append(base_name)\n",
    "\n",
    "    print(f\"\\n📂 {split.upper()} - FALL: {len(fall_files)}, ADL: {len(adl_files)}\")\n",
    "\n",
    "    # 1. REFLEJAR FALL\n",
    "    for base_name in fall_files:\n",
    "        img_path = os.path.join(img_dir, base_name + '.jpg')\n",
    "        label_path = os.path.join(lbl_dir, base_name + '.txt')\n",
    "\n",
    "        if not os.path.exists(img_path):\n",
    "            img_path = os.path.join(img_dir, base_name + '.png')\n",
    "            if not os.path.exists(img_path):\n",
    "                continue\n",
    "\n",
    "        # Reflejar imagen horizontalmente\n",
    "        img = Image.open(img_path)\n",
    "        flipped_img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        if flipped_img.mode == 'RGBA':\n",
    "            flipped_img = flipped_img.convert('RGB')\n",
    "        # Guardar imagen reflejada\n",
    "        new_img_name = base_name + '_flip.jpg'\n",
    "        flipped_img.save(os.path.join(img_dir, new_img_name))\n",
    "\n",
    "        # Reflejar label\n",
    "        with open(label_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        new_lines = []\n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            cls, x_center, y_center, width, height = parts\n",
    "            x_center = str(1.0 - float(x_center))  # invertir horizontalmente\n",
    "            new_lines.append(f\"{cls} {x_center} {y_center} {width} {height}\\n\")\n",
    "\n",
    "        with open(os.path.join(lbl_dir, base_name + '_flip.txt'), 'w') as f:\n",
    "            f.writelines(new_lines)\n",
    "\n",
    "    # 2. DUPLICAR ADL HASTA BALANCEAR\n",
    "    new_fall_total = len(fall_files) * 2\n",
    "    adl_needed = new_fall_total - len(adl_files)\n",
    "    print(f\"🔁 Se necesitan {adl_needed} duplicaciones de ADL para balancear\")\n",
    "\n",
    "    if adl_needed > 0:\n",
    "        sampled = random.choices(adl_files, k=adl_needed)\n",
    "        for i, base_name in enumerate(sampled):\n",
    "            src_img_path = os.path.join(img_dir, base_name + '.jpg')\n",
    "            if not os.path.exists(src_img_path):\n",
    "                src_img_path = os.path.join(img_dir, base_name + '.png')\n",
    "                if not os.path.exists(src_img_path):\n",
    "                    continue\n",
    "\n",
    "            src_lbl_path = os.path.join(lbl_dir, base_name + '.txt')\n",
    "            if not os.path.exists(src_lbl_path):\n",
    "                continue\n",
    "\n",
    "            # Reflejar imagen\n",
    "            img = Image.open(src_img_path)\n",
    "            flipped_img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            if flipped_img.mode == 'RGBA':\n",
    "                flipped_img = flipped_img.convert('RGB')\n",
    "            new_base = f\"{base_name}_flipdup{i}\"\n",
    "            flipped_img.save(os.path.join(img_dir, new_base + '.jpg'))\n",
    "\n",
    "            # Reflejar label\n",
    "            with open(src_lbl_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "\n",
    "            new_lines = []\n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                cls, x_center, y_center, width, height = parts\n",
    "                x_center = str(1.0 - float(x_center))\n",
    "                new_lines.append(f\"{cls} {x_center} {y_center} {width} {height}\\n\")\n",
    "\n",
    "            with open(os.path.join(lbl_dir, new_base + '.txt'), 'w') as f:\n",
    "                f.writelines(new_lines)\n",
    "    \n",
    "print(\"\\n✅ Dataset balanceado con reflejo de FALL y duplicación de ADL.\")"
   ],
   "id": "9789c883d06f6329",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📂 TRAIN - FALL: 3433, ADL: 3695\n",
      "🔁 Se necesitan 3171 duplicaciones de ADL para balancear\n",
      "\n",
      "✅ Dataset balanceado con reflejo de FALL y duplicación de ADL.\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# UR FALL",
   "id": "486caa1c070abe96"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T21:19:54.987160Z",
     "start_time": "2025-05-24T21:19:48.828607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img_dir = 'dataset/UR-Fall/all_imgs'\n",
    "label_dir = 'dataset/UR-Fall/all_labels'\n",
    "\n",
    "# Directorios de salida\n",
    "output_base = 'dataset/UR-Fall/UR_Fall_split_escenarios_v2'\n",
    "splits = ['train', 'valid', 'test']\n",
    "\n",
    "# Crear estructura de carpetas\n",
    "for split in splits:\n",
    "    os.makedirs(os.path.join(output_base, split, 'images'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_base, split, 'labels'), exist_ok=True)\n",
    "\n",
    "# Regex para extraer escenario\n",
    "def extract_scenario(filename):\n",
    "    match = re.match(r'(fall|adl)-(\\d+)', filename.lower())\n",
    "    if match:\n",
    "        scenario_type = match.group(1).upper()\n",
    "        scenario_id = int(match.group(2))\n",
    "        return f\"{scenario_type}-{scenario_id}\"\n",
    "    return None\n",
    "\n",
    "# Agrupar imágenes por escenario\n",
    "scenarios = defaultdict(list)\n",
    "\n",
    "for img_file in os.listdir(img_dir):\n",
    "    if not img_file.lower().endswith(('.jpg', '.png')):\n",
    "        continue\n",
    "    base_name = os.path.splitext(img_file)[0]\n",
    "    scenario = extract_scenario(base_name)\n",
    "    if scenario:\n",
    "        scenarios[scenario].append(base_name)\n",
    "\n",
    "# Separar escenarios en FALL y ADL\n",
    "fall_scenarios = sorted([s for s in scenarios if s.startswith('FALL')])\n",
    "adl_scenarios = sorted([s for s in scenarios if s.startswith('ADL')])\n",
    "\n",
    "print(f\"Total escenarios FALL: {len(fall_scenarios)}\")\n",
    "print(f\"Total escenarios ADL: {len(adl_scenarios)}\")\n",
    "\n",
    "# Dividir escenarios\n",
    "def split_list(scenario_list):\n",
    "    total = len(scenario_list)\n",
    "    random.seed(97)\n",
    "    random.shuffle(scenario_list)\n",
    "    n_train = int(round(total * 0.8))\n",
    "    n_valid = int(round(total * 0.1))\n",
    "    n_test = total - n_train - n_valid\n",
    "    return (\n",
    "        scenario_list[:n_train],\n",
    "        scenario_list[n_train:n_train+n_valid],\n",
    "        scenario_list[n_train+n_valid:]\n",
    "    )\n",
    "\n",
    "fall_train, fall_valid, fall_test = split_list(fall_scenarios)\n",
    "adl_train, adl_valid, adl_test = split_list(adl_scenarios)\n",
    "\n",
    "split_map = {\n",
    "    'train': fall_train + adl_train,\n",
    "    'valid': fall_valid + adl_valid,\n",
    "    'test': fall_test + adl_test,\n",
    "}\n",
    "\n",
    "# Copiar archivos a carpetas correspondientes\n",
    "for split, scenario_list in split_map.items():\n",
    "    for scenario in scenario_list:\n",
    "        for base_name in scenarios[scenario]:\n",
    "            img_ext = '.jpg' if os.path.exists(os.path.join(img_dir, base_name + '.jpg')) else '.png'\n",
    "            src_img = os.path.join(img_dir, base_name + img_ext)\n",
    "            src_lbl = os.path.join(label_dir, base_name + '.txt')\n",
    "\n",
    "            dst_img = os.path.join(output_base, split, 'images', base_name + img_ext)\n",
    "            dst_lbl = os.path.join(output_base, split, 'labels', base_name + '.txt')\n",
    "\n",
    "            if os.path.exists(src_img):\n",
    "                shutil.copy(src_img, dst_img)\n",
    "            if os.path.exists(src_lbl):\n",
    "                shutil.copy(src_lbl, dst_lbl)\n",
    "\n",
    "print(\"\\n✅ División de dataset completada correctamente.\")\n",
    "len_train = len(os.listdir('dataset/UR-Fall/UR_Fall_split_escenarios/train/images'))\n",
    "len_valid =len(os.listdir('dataset/UR-Fall/UR_Fall_split_escenarios/valid/images'))\n",
    "len_test = len(os.listdir('dataset/UR-Fall/UR_Fall_split_escenarios/test/images'))\n",
    "len_tot = len_train + len_valid + len_test\n",
    "print(f\"TRAIN: {len_train}, ratio: {(len_train/len_tot)*100}\")\n",
    "print(f\"VALID: {len_valid}, ratio: {(len_valid/len_tot)*100}\")\n",
    "print(f\"TEST: {len_test}, ratio: {(len_test/len_tot)*100}\")\n",
    "print(f\"TOTAL: {len_tot}\")"
   ],
   "id": "59a280ac95328e61",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total escenarios FALL: 30\n",
      "Total escenarios ADL: 40\n",
      "\n",
      "✅ División de dataset completada correctamente.\n",
      "TRAIN: 2305, ratio: 67.8939617083947\n",
      "VALID: 586, ratio: 17.260677466863033\n",
      "TEST: 504, ratio: 14.845360824742269\n",
      "TOTAL: 3395\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T21:20:23.235793Z",
     "start_time": "2025-05-24T21:20:23.228462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"TRAIN\")\n",
    "print(fall_train)\n",
    "print(adl_train)\n",
    "print(\"VALID\")\n",
    "print(fall_valid)\n",
    "print(adl_valid)\n",
    "print(\"TEST\")\n",
    "print(fall_test)\n",
    "print(adl_test)"
   ],
   "id": "5c72a68e13301b8f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "['FALL-20', 'FALL-18', 'FALL-24', 'FALL-9', 'FALL-30', 'FALL-23', 'FALL-29', 'FALL-13', 'FALL-12', 'FALL-14', 'FALL-28', 'FALL-22', 'FALL-8', 'FALL-16', 'FALL-19', 'FALL-11', 'FALL-27', 'FALL-6', 'FALL-17', 'FALL-3', 'FALL-4', 'FALL-25', 'FALL-1', 'FALL-26']\n",
      "['ADL-38', 'ADL-33', 'ADL-9', 'ADL-3', 'ADL-13', 'ADL-24', 'ADL-37', 'ADL-2', 'ADL-8', 'ADL-36', 'ADL-27', 'ADL-32', 'ADL-31', 'ADL-4', 'ADL-26', 'ADL-35', 'ADL-15', 'ADL-39', 'ADL-21', 'ADL-17', 'ADL-14', 'ADL-18', 'ADL-16', 'ADL-19', 'ADL-6', 'ADL-29', 'ADL-23', 'ADL-22', 'ADL-28', 'ADL-40', 'ADL-1', 'ADL-7']\n",
      "VALID\n",
      "['FALL-10', 'FALL-7', 'FALL-2']\n",
      "['ADL-25', 'ADL-5', 'ADL-11', 'ADL-10']\n",
      "TEST\n",
      "['FALL-5', 'FALL-21', 'FALL-15']\n",
      "['ADL-12', 'ADL-30', 'ADL-34', 'ADL-20']\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T21:20:57.131938Z",
     "start_time": "2025-05-24T21:20:31.422531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Directorio base del dataset\n",
    "base_dir = \"dataset/UR-Fall/UR_Fall_split_escenarios_v2\"\n",
    "#splits_v1 = ['train', 'valid', 'test']\n",
    "splits = ['train']\n",
    "class_names = {0: 'ADL', 1: 'FALL'}\n",
    "\n",
    "def count_labels(label_file):\n",
    "    with open(label_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    fall = sum(1 for l in lines if l.startswith('1 '))\n",
    "    adl = sum(1 for l in lines if l.startswith('0 '))\n",
    "    return adl, fall\n",
    "\n",
    "for split in splits:\n",
    "    img_dir = os.path.join(base_dir, split, 'images')\n",
    "    lbl_dir = os.path.join(base_dir, split, 'labels')\n",
    "\n",
    "    adl_files = []\n",
    "    fall_files = []\n",
    "\n",
    "    for label_file in os.listdir(lbl_dir):\n",
    "        if not label_file.endswith('.txt'):\n",
    "            continue\n",
    "        full_path = os.path.join(lbl_dir, label_file)\n",
    "        adl_count, fall_count = count_labels(full_path)\n",
    "\n",
    "        base_name = os.path.splitext(label_file)[0]\n",
    "        if fall_count > 0:\n",
    "            fall_files.append(base_name)\n",
    "        elif adl_count > 0:\n",
    "            adl_files.append(base_name)\n",
    "\n",
    "    print(f\"\\n📂 {split.upper()} - FALL: {len(fall_files)}, ADL: {len(adl_files)}\")\n",
    "\n",
    "    # 1. REFLEJAR FALL\n",
    "    for base_name in fall_files:\n",
    "        img_path = os.path.join(img_dir, base_name + '.jpg')\n",
    "        label_path = os.path.join(lbl_dir, base_name + '.txt')\n",
    "\n",
    "        if not os.path.exists(img_path):\n",
    "            img_path = os.path.join(img_dir, base_name + '.png')\n",
    "            if not os.path.exists(img_path):\n",
    "                continue\n",
    "\n",
    "        # Reflejar imagen horizontalmente\n",
    "        img = Image.open(img_path)\n",
    "        flipped_img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        if flipped_img.mode == 'RGBA':\n",
    "            flipped_img = flipped_img.convert('RGB')\n",
    "        # Guardar imagen reflejada\n",
    "        new_img_name = base_name + '_flip.jpg'\n",
    "        flipped_img.save(os.path.join(img_dir, new_img_name))\n",
    "\n",
    "        # Reflejar label\n",
    "        with open(label_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        new_lines = []\n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            cls, x_center, y_center, width, height = parts\n",
    "            x_center = str(1.0 - float(x_center))  # invertir horizontalmente\n",
    "            new_lines.append(f\"{cls} {x_center} {y_center} {width} {height}\\n\")\n",
    "\n",
    "        with open(os.path.join(lbl_dir, base_name + '_flip.txt'), 'w') as f:\n",
    "            f.writelines(new_lines)\n",
    "\n",
    "    # 2. DUPLICAR ADL HASTA BALANCEAR\n",
    "    new_fall_total = len(fall_files) * 2\n",
    "    adl_needed = new_fall_total - len(adl_files)\n",
    "    print(f\"🔁 Se necesitan {adl_needed} duplicaciones de ADL para balancear\")\n",
    "\n",
    "    if adl_needed > 0:\n",
    "        sampled = random.choices(adl_files, k=adl_needed)\n",
    "        for i, base_name in enumerate(sampled):\n",
    "            src_img_path = os.path.join(img_dir, base_name + '.jpg')\n",
    "            if not os.path.exists(src_img_path):\n",
    "                src_img_path = os.path.join(img_dir, base_name + '.png')\n",
    "                if not os.path.exists(src_img_path):\n",
    "                    continue\n",
    "\n",
    "            src_lbl_path = os.path.join(lbl_dir, base_name + '.txt')\n",
    "            if not os.path.exists(src_lbl_path):\n",
    "                continue\n",
    "\n",
    "            # Reflejar imagen\n",
    "            img = Image.open(src_img_path)\n",
    "            flipped_img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            if flipped_img.mode == 'RGBA':\n",
    "                flipped_img = flipped_img.convert('RGB')\n",
    "            new_base = f\"{base_name}_flipdup{i}\"\n",
    "            flipped_img.save(os.path.join(img_dir, new_base + '.jpg'))\n",
    "\n",
    "            # Reflejar label\n",
    "            with open(src_lbl_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "\n",
    "            new_lines = []\n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                cls, x_center, y_center, width, height = parts\n",
    "                x_center = str(1.0 - float(x_center))\n",
    "                new_lines.append(f\"{cls} {x_center} {y_center} {width} {height}\\n\")\n",
    "\n",
    "            with open(os.path.join(lbl_dir, new_base + '.txt'), 'w') as f:\n",
    "                f.writelines(new_lines)\n",
    "\n",
    "print(\"\\n✅ Dataset balanceado con reflejo de FALL y duplicación de ADL.\")"
   ],
   "id": "cf0566b2d2645722",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📂 TRAIN - FALL: 481, ADL: 1343\n",
      "🔁 Se necesitan -381 duplicaciones de ADL para balancear\n",
      "\n",
      "✅ Dataset balanceado con reflejo de FALL y duplicación de ADL.\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T21:21:32.246393Z",
     "start_time": "2025-05-24T21:21:31.358564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Directorio base\n",
    "base_dir = \"dataset/UR-Fall/UR_Fall_split_escenarios_v2\"\n",
    "splits = ['train', 'valid', 'test']\n",
    "class_names = {0: 'ADL', 1: 'FALL'}\n",
    "\n",
    "# Inicializar contadores\n",
    "distribution = {split: {0: 0, 1: 0} for split in splits}\n",
    "\n",
    "for split in splits:\n",
    "    label_path = os.path.join(base_dir, split, 'labels')\n",
    "    for filename in os.listdir(label_path):\n",
    "        if not filename.endswith('.txt'):\n",
    "            continue\n",
    "        with open(os.path.join(label_path, filename), 'r') as f:\n",
    "            for line in f:\n",
    "                class_id = int(line.strip().split()[0])\n",
    "                if class_id in [0, 1]:\n",
    "                    distribution[split][class_id] += 1\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"📊 Distribución de clases:\")\n",
    "for split in splits:\n",
    "    print(f\"\\n{split.upper()}:\")\n",
    "    for class_id, count in distribution[split].items():\n",
    "        print(f\"  {class_names[class_id]} (clase {class_id}): {count}\")"
   ],
   "id": "2a94f65ac888ccfd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Distribución de clases:\n",
      "\n",
      "TRAIN:\n",
      "  ADL (clase 0): 1356\n",
      "  FALL (clase 1): 962\n",
      "\n",
      "VALID:\n",
      "  ADL (clase 0): 336\n",
      "  FALL (clase 1): 125\n",
      "\n",
      "TEST:\n",
      "  ADL (clase 0): 132\n",
      "  FALL (clase 1): 126\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T21:21:36.464981Z",
     "start_time": "2025-05-24T21:21:36.447921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "len_train = len(os.listdir('dataset/UR-Fall/UR_Fall_split_escenarios_v2/train/images'))\n",
    "len_valid =len(os.listdir('dataset/UR-Fall/UR_Fall_split_escenarios_v2/valid/images'))\n",
    "len_test = len(os.listdir('dataset/UR-Fall/UR_Fall_split_escenarios_v2/test/images'))\n",
    "len_tot = len_train + len_valid + len_test\n",
    "print(f\"TRAIN: {len_train}, ratio: {(len_train/len_tot)*100}\")\n",
    "print(f\"VALID: {len_valid}, ratio: {(len_valid/len_tot)*100}\")\n",
    "print(f\"TEST: {len_test}, ratio: {(len_test/len_tot)*100}\")\n",
    "print(f\"TOTAL: {len_tot}\")"
   ],
   "id": "db11550170b495fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: 2305, ratio: 76.22354497354497\n",
      "VALID: 461, ratio: 15.244708994708994\n",
      "TEST: 258, ratio: 8.531746031746032\n",
      "TOTAL: 3024\n"
     ]
    }
   ],
   "execution_count": 37
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
