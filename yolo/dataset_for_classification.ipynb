{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-02T20:29:46.203588Z",
     "start_time": "2025-05-02T20:13:08.738563Z"
    }
   },
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import cv2\n",
    "\n",
    "# Directorios actuales\n",
    "base_dir = \"dataset/Merged_Dataset\"  # Cambia si tu base es diferente\n",
    "splits = [\"train\", \"valid\", \"test\"]\n",
    "\n",
    "# Directorio de salida\n",
    "output_base = \"dataset/Merged_Dataset_for_classification\"\n",
    "\n",
    "extensions = [\".jpg\", \".jpeg\", \".png\"]\n",
    "\n",
    "# Contador de imÃ¡genes por clase y split\n",
    "counter = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "def yolo_to_pixel_coords(yolo_box, img_width, img_height):\n",
    "    class_id, x_center, y_center, width, height = map(float, yolo_box)\n",
    "    x_center *= img_width\n",
    "    y_center *= img_height\n",
    "    width *= img_width\n",
    "    height *= img_height\n",
    "\n",
    "    x1 = int(x_center - width / 2)\n",
    "    y1 = int(y_center - height / 2)\n",
    "    x2 = int(x_center + width / 2)\n",
    "    y2 = int(y_center + height / 2)\n",
    "\n",
    "    # Clipping to image bounds\n",
    "    x1, y1 = max(0, x1), max(0, y1)\n",
    "    x2, y2 = min(img_width, x2), min(img_height, y2)\n",
    "\n",
    "    return int(class_id), x1, y1, x2, y2\n",
    "\n",
    "for split in splits:\n",
    "    img_dir = Path(base_dir) / split / \"images\"\n",
    "    lbl_dir = Path(base_dir) / split / \"labels\"\n",
    "\n",
    "    all_images = []\n",
    "    for ext in extensions:\n",
    "        all_images.extend(list(img_dir.glob(f\"*{ext}\")))\n",
    "\n",
    "    print(f\"\\nProcesando {split} ({len(all_images)} imÃ¡genes)...\")\n",
    "\n",
    "    for img_path in tqdm(all_images, desc=f\"{split}\"):\n",
    "        label_file = lbl_dir / (img_path.stem + \".txt\")\n",
    "        if not label_file.exists():\n",
    "            continue\n",
    "\n",
    "        image = cv2.imread(str(img_path))\n",
    "        if image is None:\n",
    "            continue\n",
    "        h, w = image.shape[:2]\n",
    "\n",
    "        with open(label_file, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        for i, line in enumerate(lines):\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) != 5:\n",
    "                continue\n",
    "            class_id, x1, y1, x2, y2 = yolo_to_pixel_coords(parts, w, h)\n",
    "\n",
    "            cropped = image[y1:y2, x1:x2]\n",
    "            if cropped.size == 0:\n",
    "                continue\n",
    "\n",
    "            # Carpeta destino\n",
    "            dest_dir = Path(output_base) / split / str(class_id)\n",
    "            dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            # Nombre Ãºnico por si hay mÃºltiples objetos en una imagen\n",
    "            output_name = f\"{img_path.stem}_{i}{img_path.suffix}\"\n",
    "            output_path = dest_dir / output_name\n",
    "            cv2.imwrite(str(output_path), cropped)\n",
    "\n",
    "            counter[split][str(class_id)] += 1\n",
    "\n",
    "# Mostrar resumen\n",
    "print(\"\\nðŸ“Š Resumen de imÃ¡genes por clase y split:\")\n",
    "for split in splits:\n",
    "    print(f\"\\nðŸ”¹ {split.upper()}:\")\n",
    "    for class_id in sorted(counter[split]):\n",
    "        print(f\"  Clase {class_id}: {counter[split][class_id]} imÃ¡genes\")\n",
    "\n",
    "print(\"\\nâœ… Dataset clasificado y recortado correctamente.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando train (25864 imÃ¡genes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25864/25864 [13:07<00:00, 32.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando valid (3981 imÃ¡genes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3981/3981 [02:05<00:00, 31.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando test (2592 imÃ¡genes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2592/2592 [01:22<00:00, 31.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Resumen de imÃ¡genes por clase y split:\n",
      "\n",
      "ðŸ”¹ TRAIN:\n",
      "  Clase 0: 16498 imÃ¡genes\n",
      "  Clase 1: 9371 imÃ¡genes\n",
      "\n",
      "ðŸ”¹ VALID:\n",
      "  Clase 0: 2512 imÃ¡genes\n",
      "  Clase 1: 1473 imÃ¡genes\n",
      "\n",
      "ðŸ”¹ TEST:\n",
      "  Clase 0: 1628 imÃ¡genes\n",
      "  Clase 1: 964 imÃ¡genes\n",
      "\n",
      "âœ… Dataset clasificado y recortado correctamente.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
