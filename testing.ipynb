{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-20T23:20:47.253148Z",
     "start_time": "2025-04-20T23:20:42.139188Z"
    }
   },
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.layers import MultiHeadAttention\n",
    "import mediapipe as mp"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T23:20:47.254156Z",
     "start_time": "2025-04-20T23:20:47.254156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)"
   ],
   "id": "90620e5565b31b65",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def calculate_com(landmarks):\n",
    "    \"\"\"\n",
    "    Calcula el centro de masa (promedio de las posiciones de las articulaciones clave).\n",
    "    Utiliza las caderas y hombros para el cálculo.\n",
    "    \"\"\"\n",
    "    # Puntos clave: Caderas y Hombros\n",
    "    left_hip = np.array([landmarks[mp_pose.PoseLandmark.LEFT_HIP].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.LEFT_HIP].y,\n",
    "                         landmarks[mp_pose.PoseLandmark.LEFT_HIP].z])\n",
    "\n",
    "    right_hip = np.array([landmarks[mp_pose.PoseLandmark.RIGHT_HIP].x,\n",
    "                          landmarks[mp_pose.PoseLandmark.RIGHT_HIP].y,\n",
    "                          landmarks[mp_pose.PoseLandmark.RIGHT_HIP].z])\n",
    "\n",
    "    left_shoulder = np.array([landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].x,\n",
    "                              landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].y,\n",
    "                              landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].z])\n",
    "\n",
    "    right_shoulder = np.array([landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].x,\n",
    "                               landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].y,\n",
    "                               landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].z])\n",
    "\n",
    "    # Calcula el centro de masa como el promedio de los puntos clave\n",
    "    com = (left_hip + right_hip + left_shoulder + right_shoulder) / 4\n",
    "    return com\n",
    "\n",
    "\n",
    "def calculate_torso_orientation(landmarks):\n",
    "    \"\"\"\n",
    "    Calcula la orientación del torso usando los hombros y caderas.\n",
    "    \"\"\"\n",
    "    # Puntos clave: Hombros y Caderas\n",
    "    left_shoulder = np.array([landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].x,\n",
    "                              landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].y,\n",
    "                              landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].z])\n",
    "\n",
    "    right_shoulder = np.array([landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].x,\n",
    "                               landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].y,\n",
    "                               landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].z])\n",
    "\n",
    "    left_hip = np.array([landmarks[mp_pose.PoseLandmark.LEFT_HIP].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.LEFT_HIP].y,\n",
    "                         landmarks[mp_pose.PoseLandmark.LEFT_HIP].z])\n",
    "\n",
    "    right_hip = np.array([landmarks[mp_pose.PoseLandmark.RIGHT_HIP].x,\n",
    "                          landmarks[mp_pose.PoseLandmark.RIGHT_HIP].y,\n",
    "                          landmarks[mp_pose.PoseLandmark.RIGHT_HIP].z])\n",
    "\n",
    "    # Vector hombros (dirección entre los hombros)\n",
    "    shoulder_vector = right_shoulder - left_shoulder\n",
    "\n",
    "    # Centro de las caderas\n",
    "    hip_center = (left_hip + right_hip) / 2\n",
    "\n",
    "    # Vector torso (dirección entre los hombros y el centro de las caderas)\n",
    "    torso_vector = hip_center - (left_shoulder + right_shoulder) / 2\n",
    "\n",
    "    # Producto cruzado para obtener la normal al plano del torso\n",
    "    torso_normal = np.cross(shoulder_vector, torso_vector)\n",
    "\n",
    "    # Normalización del vector normal\n",
    "    torso_normal = torso_normal / np.linalg.norm(torso_normal)\n",
    "\n",
    "    return torso_normal\n"
   ],
   "id": "bae6cd52ad3829ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T23:20:47.258209Z",
     "start_time": "2025-04-20T23:20:47.258209Z"
    }
   },
   "cell_type": "code",
   "source": "model = load_model('fall_detection_model.keras')",
   "id": "f1f1971dd7b2c44d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T23:20:47.261727Z",
     "start_time": "2025-04-20T23:20:47.261727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "WINDOW_SIZE = 130\n",
    "features_dq = deque(maxlen=WINDOW_SIZE)\n",
    "lands_dq = deque(maxlen=WINDOW_SIZE)\n",
    "\n",
    "# Video en vivo (cámara)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frames_per_second = 6\n",
    "frame_skip = int(fps // frames_per_second)\n",
    "frame_count = 0\n",
    "\n",
    "# Variables para velocidad y aceleración\n",
    "prev_landmarks = None\n",
    "prev_velocity = None\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_count += 1\n",
    "    if frame_count % frame_skip != 0:\n",
    "        continue  # Saltar este frame\n",
    "    frame_count = 0\n",
    "    # Procesamiento de imagen\n",
    "    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(image_rgb)\n",
    "\n",
    "    if results.pose_world_landmarks:\n",
    "        landmarks = results.pose_world_landmarks.landmark\n",
    "        joint_index = 0  # Usualmente la cadera o nariz (ajusta según tu entrenamiento)\n",
    "        flat_pose = []\n",
    "        if prev_landmarks is not None:\n",
    "            x, y, z = landmarks[joint_index].x, landmarks[joint_index].y, landmarks[joint_index].z\n",
    "            x_prev, y_prev, z_prev = prev_landmarks[joint_index]\n",
    "\n",
    "            dx, dy, dz = x - x_prev, y - y_prev, z - z_prev\n",
    "            displacement = np.sqrt(dx**2 + dy**2 + dz**2)\n",
    "\n",
    "            velocity_x, velocity_y, velocity_z = dx, dy, dz\n",
    "            velocity = np.sqrt(velocity_x**2 + velocity_y**2 + velocity_z**2)\n",
    "\n",
    "            if prev_velocity is not None:\n",
    "                acceleration_x = velocity_x - prev_velocity[0]\n",
    "                acceleration_y = velocity_y - prev_velocity[1]\n",
    "                acceleration_z = velocity_z - prev_velocity[2]\n",
    "                acceleration = np.sqrt(acceleration_x**2 + acceleration_y**2 + acceleration_z**2)\n",
    "            else:\n",
    "                acceleration = 0\n",
    "\n",
    "            tangent_angle = np.arctan2(dy, dx) * (180 / np.pi)\n",
    "            com = calculate_com(landmarks)\n",
    "            torso_normal = calculate_torso_orientation(landmarks)\n",
    "\n",
    "            land = [(lm.x, lm.y, lm.z) for lm in landmarks]\n",
    "            features = [\n",
    "                displacement,\n",
    "                velocity,\n",
    "                acceleration,\n",
    "                tangent_angle,\n",
    "                com[0], com[1], com[2],\n",
    "                torso_normal[0], torso_normal[1], torso_normal[2]\n",
    "            ]\n",
    "            \n",
    "            for x, y, z in land:\n",
    "                flat_pose.extend([x, y, z])\n",
    "            lands_dq.append(flat_pose)\n",
    "            features_dq.append(features)\n",
    "            prev_velocity = (velocity_x, velocity_y, velocity_z)\n",
    "        #print(frame_features_buffer)\n",
    "            # Solo predecir si tenemos suficiente historial\n",
    "        if len(lands_dq) == WINDOW_SIZE:\n",
    "            #input_array = np.array(frame_features_buffer)[None, :, :]  # Shape: (1, 30, 10)\n",
    "            combined_seq = [f + l for f, l in zip(features_dq, lands_dq)]\n",
    "            input_array = np.array(list(combined_seq), dtype=np.float32)\n",
    "            input_array = np.expand_dims(input_array, axis=0)\n",
    "            #print(input_array.shape)\n",
    "            prediction = model.predict(input_array)\n",
    "            predicted_label = np.argmax(prediction)\n",
    "\n",
    "            label = \"Caída\" if predicted_label == 1 else \"Normal\"\n",
    "            print(f\"Predicción: {label} (confianza: {prediction[0][predicted_label]:.2f})\")\n",
    "\n",
    "            # Mostrar en pantalla\n",
    "            cv2.putText(frame, label, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.2,\n",
    "                        (0, 0, 255) if predicted_label == 1 else (0, 255, 0), 3)\n",
    "            \"\"\"\n",
    "        elif len(frame_features_buffer) >= 60:\n",
    "            num_pose_dims = len(frame_features_buffer[0]) if frame_features_buffer else 130  # 33 puntos x 3 coords\n",
    "            padding_poses = [[0.0] * num_pose_dims] * (WINDOW_SIZE - len(frame_features_buffer))\n",
    "            frame_features_buffer.extend(padding_poses)\n",
    "            \"\"\"\n",
    "            \n",
    "\n",
    "        prev_landmarks = [(lm.x, lm.y, lm.z) for lm in landmarks]\n",
    "\n",
    "    # Mostrar el video\n",
    "    cv2.imshow(\"Detección de Caídas\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:  # Presiona ESC para salir\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "d7818b13b55bcd79",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"combined_padded.csv\")\n",
    "# Asegúrate de que los campos 'features' y 'poses_sec' son listas\n",
    "def safe_literal_eval(val):\n",
    "    # Maneja valores nulos/faltantes devolviendo lista vacía o None según prefieras\n",
    "    if pd.isna(val):\n",
    "        return [] # O manejar de otra forma si es necesario\n",
    "    if isinstance(val, str):\n",
    "        try:\n",
    "            return ast.literal_eval(val)\n",
    "        except (ValueError, SyntaxError):\n",
    "            print(f\"Advertencia: No se pudo evaluar: {val}\")\n",
    "            return [] # O manejar de otra forma\n",
    "    return val # Si ya es una lista/otro tipo\n",
    "df['features'] = df['features'].apply(safe_literal_eval)\n",
    "df['poses_sec'] = df['poses_sec'].apply(safe_literal_eval)\n",
    "df = df[df['video_filename'] == '03_4 (10).mp4']\n",
    "df"
   ],
   "id": "484a6bd5afd98dad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for i, (feats, lms) in enumerate(zip(df['features'], df['poses_sec'])):\n",
    "    if not feats or not lms:\n",
    "        print(f\"Advertencia: Lista vacía encontrada en índice {i}. Saltando muestra.\")\n",
    "        continue # O manejar añadiendo ceros si es apropiado\n",
    "\n",
    "    # Verifica si las longitudes coinciden antes de hacer zip\n",
    "    if len(feats) != len(lms):\n",
    "        print(f\"Advertencia: Longitudes no coinciden en índice {i}. feats: {len(feats)}, lms: {len(lms)}. Usando la longitud menor.\")\n",
    "        min_len = min(len(feats), len(lms))\n",
    "        feats = feats[:min_len]\n",
    "        lms = lms[:min_len]\n",
    "\n",
    "    combined_seq = [f + l for f, l in zip(feats, lms)]\n",
    "    print(combined_seq)\n",
    "    print(len(combined_seq))\n",
    "    input_array = np.array(list(combined_seq), dtype=np.float32)\n",
    "    input_array = np.expand_dims(input_array, axis=0)\n",
    "    print(input_array.shape)"
   ],
   "id": "753d473408a53e0d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "prediction = model.predict(input_array)\n",
    "predicted_label = np.argmax(prediction)\n",
    "print(prediction)\n",
    "label = \"Caída\" if predicted_label == 1 else \"Normal\"\n",
    "print(f\"Predicción: {label} (confianza: {prediction[0][predicted_label]:.2f})\")"
   ],
   "id": "39cc880c77a6cffa",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
