{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8133a99d",
   "metadata": {},
   "source": [
    "# Perform Experiments with DeepFace on LFW dataset"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T19:10:46.005577Z",
     "start_time": "2025-05-16T19:09:37.174924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install deepface\n",
    "!pip install ultralytics --no-deps"
   ],
   "id": "6ec97db2d043f99f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "5aab0cbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T14:22:25.625333Z",
     "start_time": "2025-05-15T14:22:13.240950Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import fetch_lfw_pairs\n",
    "from deepface import DeepFace"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Franco\\.conda\\envs\\fall_detect\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "64c9ed9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T23:46:06.351481Z",
     "start_time": "2025-05-14T23:46:06.345277Z"
    }
   },
   "source": [
    "print(f\"This experiment is done with pip package of deepface with {DeepFace.__version__} version\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This experiment is done with pip package of deepface with 0.0.93 version\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "feaec973",
   "metadata": {},
   "source": [
    "### Configuration Sets"
   ]
  },
  {
   "cell_type": "code",
   "id": "453104b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T14:23:13.433189Z",
     "start_time": "2025-05-15T14:23:13.424310Z"
    }
   },
   "source": [
    "# all configuration alternatives for 4 dimensions of arguments\n",
    "alignment = True\n",
    "models = [\"Facenet\", \"VGG-Face\", \"ArcFace\", \"GhostFaceNet\", \"OpenFace\"]\n",
    "detectors = [\"retinaface\", \"centerface\", \"yunet\", \"yolov8\"]\n",
    "metrics = [\"euclidean\", \"euclidean_l2\", \"cosine\"]\n",
    "expand_percentage = 0\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "c9aeb57a",
   "metadata": {},
   "source": [
    "### Create Required Folders if necessary"
   ]
  },
  {
   "cell_type": "code",
   "id": "671d8a00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T23:46:11.527881Z",
     "start_time": "2025-05-14T23:46:11.520873Z"
    }
   },
   "source": [
    "target_paths = [\"lfwe\", \"dataset\", \"outputs\", \"outputs/test\", \"results\", \"lfwe/test\"]\n",
    "for target_path in target_paths:\n",
    "    if not os.path.exists(target_path):\n",
    "        os.mkdir(target_path)\n",
    "        print(f\"{target_path} created\")"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "fc31f03a",
   "metadata": {},
   "source": [
    "### Load LFW Dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "721a7d70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T14:22:25.634126Z",
     "start_time": "2025-05-15T14:22:25.629487Z"
    }
   },
   "source": [
    "pairs_touch = \"outputs/test_lfwe.txt\"\n",
    "instances = 1000 #pairs.shape[0]"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "010184d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T14:22:25.652820Z",
     "start_time": "2025-05-15T14:22:25.645058Z"
    }
   },
   "source": [
    "# https://scikit-learn.org/stable/auto_examples/applications/plot_face_recognition.html#sphx-glr-auto-examples-applications-plot-face-recognition-py\n",
    "\n",
    "target_path = \"dataset/test_lfw.npy\"\n",
    "labels_path = \"dataset/test_labels.npy\"\n",
    "\n",
    "if not os.path.exists(target_path):\n",
    "    fetch_lfw_pairs = fetch_lfw_pairs(subset = 'test', color = True\n",
    "                                  , resize = 0.4\n",
    "                                  , funneled = False\n",
    "                                  , slice_=None\n",
    "                                 )\n",
    "    pairs = fetch_lfw_pairs.pairs\n",
    "    labels = fetch_lfw_pairs.target\n",
    "    target_names = fetch_lfw_pairs.target_names\n",
    "    np.save(target_path, pairs)\n",
    "    np.save(labels_path, labels)\n",
    "else:\n",
    "    if not os.path.exists(pairs_touch):\n",
    "        # loading pairs takes some time. but if we extract these pairs as image, no need to load it anymore\n",
    "        pairs = np.load(target_path)\n",
    "    labels = np.load(labels_path)    "
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "005f582e",
   "metadata": {},
   "source": [
    "### Save LFW image pairs into file system"
   ]
  },
  {
   "cell_type": "code",
   "id": "5bc23313",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T14:23:37.932541Z",
     "start_time": "2025-05-15T14:23:37.669840Z"
    }
   },
   "source": [
    "for i in tqdm(range(0, instances)):\n",
    "    img1_target = f\"lfwe/test/{i}_1.jpg\"\n",
    "    img2_target = f\"lfwe/test/{i}_2.jpg\"\n",
    "    \n",
    "    if not os.path.exists(img1_target):\n",
    "        img1 = pairs[i][0]\n",
    "        # plt.imsave(img1_target, img1/255) #works for my mac\n",
    "        plt.imsave(img1_target, img1) #works for my debian\n",
    "    \n",
    "    if not os.path.exists(img2_target):\n",
    "        img2 = pairs[i][1]\n",
    "        # plt.imsave(img2_target, img2/255) #works for my mac\n",
    "        plt.imsave(img2_target, img2) #works for my debian\n",
    "    \n",
    "if not os.path.exists(pairs_touch):\n",
    "    open(pairs_touch,'a').close()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 4119.73it/s]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "6f8fa8fa",
   "metadata": {},
   "source": [
    "### Perform Experiments\n",
    "\n",
    "This block will save the experiments results in outputs folder"
   ]
  },
  {
   "cell_type": "code",
   "id": "e7fba936",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T14:23:40.420349Z",
     "start_time": "2025-05-15T14:23:40.054696Z"
    }
   },
   "source": [
    "for model_name in models:\n",
    "    for detector_backend in detectors:\n",
    "        for distance_metric in metrics:\n",
    "\n",
    "            alignment_text = \"aligned\"\n",
    "            task = f\"{model_name}_{detector_backend}_{distance_metric}_{alignment_text}\"\n",
    "            output_file = f\"outputs/test/{task}.csv\"\n",
    "            if os.path.exists(output_file):\n",
    "                 #print(f\"{output_file} is available already\")\n",
    "                 continue\n",
    "\n",
    "            distances = []\n",
    "            for i in tqdm(range(0, instances), desc = task):\n",
    "                img1_target = f\"lfwe/test/{i}_1.jpg\"\n",
    "                img2_target = f\"lfwe/test/{i}_2.jpg\"\n",
    "                result = DeepFace.verify(\n",
    "                    img1_path=img1_target,\n",
    "                    img2_path=img2_target,\n",
    "                    model_name=model_name,\n",
    "                    detector_backend=detector_backend,\n",
    "                    distance_metric=distance_metric,\n",
    "                    align=alignment,\n",
    "                    enforce_detection=False,\n",
    "                    expand_percentage=expand_percentage,\n",
    "                )\n",
    "                distance = result[\"distance\"]\n",
    "                distances.append(distance)\n",
    "            # -----------------------------------\n",
    "            df = pd.DataFrame(list(labels), columns = [\"actuals\"])\n",
    "            df[\"distances\"] = distances\n",
    "            df.to_csv(output_file, index=False)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Facenet_yolo_euclidean_aligned:   0%|          | 0/1000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception while processing img1_path",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\fall_detect\\Lib\\site-packages\\deepface\\modules\\verification.py:167\u001B[39m, in \u001B[36mverify.<locals>.extract_embeddings_and_facial_areas\u001B[39m\u001B[34m(img_path, index)\u001B[39m\n\u001B[32m    166\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m167\u001B[39m     img_embeddings, img_facial_areas = __extract_faces_and_embeddings(\n\u001B[32m    168\u001B[39m         img_path=img_path,\n\u001B[32m    169\u001B[39m         model_name=model_name,\n\u001B[32m    170\u001B[39m         detector_backend=detector_backend,\n\u001B[32m    171\u001B[39m         enforce_detection=enforce_detection,\n\u001B[32m    172\u001B[39m         align=align,\n\u001B[32m    173\u001B[39m         expand_percentage=expand_percentage,\n\u001B[32m    174\u001B[39m         normalization=normalization,\n\u001B[32m    175\u001B[39m         anti_spoofing=anti_spoofing,\n\u001B[32m    176\u001B[39m     )\n\u001B[32m    177\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\fall_detect\\Lib\\site-packages\\deepface\\modules\\verification.py:234\u001B[39m, in \u001B[36m__extract_faces_and_embeddings\u001B[39m\u001B[34m(img_path, model_name, detector_backend, enforce_detection, align, expand_percentage, normalization, anti_spoofing)\u001B[39m\n\u001B[32m    232\u001B[39m facial_areas = []\n\u001B[32m--> \u001B[39m\u001B[32m234\u001B[39m img_objs = detection.extract_faces(\n\u001B[32m    235\u001B[39m     img_path=img_path,\n\u001B[32m    236\u001B[39m     detector_backend=detector_backend,\n\u001B[32m    237\u001B[39m     grayscale=\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m    238\u001B[39m     enforce_detection=enforce_detection,\n\u001B[32m    239\u001B[39m     align=align,\n\u001B[32m    240\u001B[39m     expand_percentage=expand_percentage,\n\u001B[32m    241\u001B[39m     anti_spoofing=anti_spoofing,\n\u001B[32m    242\u001B[39m )\n\u001B[32m    244\u001B[39m \u001B[38;5;66;03m# find embeddings for each face\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\fall_detect\\Lib\\site-packages\\deepface\\modules\\detection.py:95\u001B[39m, in \u001B[36mextract_faces\u001B[39m\u001B[34m(img_path, detector_backend, enforce_detection, align, expand_percentage, grayscale, color_face, normalize_face, anti_spoofing)\u001B[39m\n\u001B[32m     94\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m95\u001B[39m     face_objs = detect_faces(\n\u001B[32m     96\u001B[39m         detector_backend=detector_backend,\n\u001B[32m     97\u001B[39m         img=img,\n\u001B[32m     98\u001B[39m         align=align,\n\u001B[32m     99\u001B[39m         expand_percentage=expand_percentage,\n\u001B[32m    100\u001B[39m     )\n\u001B[32m    102\u001B[39m \u001B[38;5;66;03m# in case of no face found\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\fall_detect\\Lib\\site-packages\\deepface\\modules\\detection.py:206\u001B[39m, in \u001B[36mdetect_faces\u001B[39m\u001B[34m(detector_backend, img, align, expand_percentage)\u001B[39m\n\u001B[32m    204\u001B[39m height, width, _ = img.shape\n\u001B[32m--> \u001B[39m\u001B[32m206\u001B[39m face_detector: Detector = modeling.build_model(\n\u001B[32m    207\u001B[39m     task=\u001B[33m\"\u001B[39m\u001B[33mface_detector\u001B[39m\u001B[33m\"\u001B[39m, model_name=detector_backend\n\u001B[32m    208\u001B[39m )\n\u001B[32m    210\u001B[39m \u001B[38;5;66;03m# validate expand percentage score\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\fall_detect\\Lib\\site-packages\\deepface\\modules\\modeling.py:98\u001B[39m, in \u001B[36mbuild_model\u001B[39m\u001B[34m(task, model_name)\u001B[39m\n\u001B[32m     97\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m98\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mInvalid model_name passed - \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtask\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m    100\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m cached_models[task][model_name]\n",
      "\u001B[31mValueError\u001B[39m: Invalid model_name passed - face_detector/yolo",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[12]\u001B[39m\u001B[32m, line 18\u001B[39m\n\u001B[32m     16\u001B[39m img1_target = \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mlfwe/test/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m_1.jpg\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     17\u001B[39m img2_target = \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mlfwe/test/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m_2.jpg\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m18\u001B[39m result = DeepFace.verify(\n\u001B[32m     19\u001B[39m     img1_path=img1_target,\n\u001B[32m     20\u001B[39m     img2_path=img2_target,\n\u001B[32m     21\u001B[39m     model_name=model_name,\n\u001B[32m     22\u001B[39m     detector_backend=detector_backend,\n\u001B[32m     23\u001B[39m     distance_metric=distance_metric,\n\u001B[32m     24\u001B[39m     align=alignment,\n\u001B[32m     25\u001B[39m     enforce_detection=\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m     26\u001B[39m     expand_percentage=expand_percentage,\n\u001B[32m     27\u001B[39m )\n\u001B[32m     28\u001B[39m distance = result[\u001B[33m\"\u001B[39m\u001B[33mdistance\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m     29\u001B[39m distances.append(distance)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\fall_detect\\Lib\\site-packages\\deepface\\DeepFace.py:150\u001B[39m, in \u001B[36mverify\u001B[39m\u001B[34m(img1_path, img2_path, model_name, detector_backend, distance_metric, enforce_detection, align, expand_percentage, normalization, silent, threshold, anti_spoofing)\u001B[39m\n\u001B[32m     70\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mverify\u001B[39m(\n\u001B[32m     71\u001B[39m     img1_path: Union[\u001B[38;5;28mstr\u001B[39m, np.ndarray, List[\u001B[38;5;28mfloat\u001B[39m]],\n\u001B[32m     72\u001B[39m     img2_path: Union[\u001B[38;5;28mstr\u001B[39m, np.ndarray, List[\u001B[38;5;28mfloat\u001B[39m]],\n\u001B[32m   (...)\u001B[39m\u001B[32m     82\u001B[39m     anti_spoofing: \u001B[38;5;28mbool\u001B[39m = \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m     83\u001B[39m ) -> Dict[\u001B[38;5;28mstr\u001B[39m, Any]:\n\u001B[32m     84\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m     85\u001B[39m \u001B[33;03m    Verify if an image pair represents the same person or different persons.\u001B[39;00m\n\u001B[32m     86\u001B[39m \u001B[33;03m    Args:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    147\u001B[39m \u001B[33;03m        - 'time' (float): Time taken for the verification process in seconds.\u001B[39;00m\n\u001B[32m    148\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m150\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m verification.verify(\n\u001B[32m    151\u001B[39m         img1_path=img1_path,\n\u001B[32m    152\u001B[39m         img2_path=img2_path,\n\u001B[32m    153\u001B[39m         model_name=model_name,\n\u001B[32m    154\u001B[39m         detector_backend=detector_backend,\n\u001B[32m    155\u001B[39m         distance_metric=distance_metric,\n\u001B[32m    156\u001B[39m         enforce_detection=enforce_detection,\n\u001B[32m    157\u001B[39m         align=align,\n\u001B[32m    158\u001B[39m         expand_percentage=expand_percentage,\n\u001B[32m    159\u001B[39m         normalization=normalization,\n\u001B[32m    160\u001B[39m         silent=silent,\n\u001B[32m    161\u001B[39m         threshold=threshold,\n\u001B[32m    162\u001B[39m         anti_spoofing=anti_spoofing,\n\u001B[32m    163\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\fall_detect\\Lib\\site-packages\\deepface\\modules\\verification.py:181\u001B[39m, in \u001B[36mverify\u001B[39m\u001B[34m(img1_path, img2_path, model_name, detector_backend, distance_metric, enforce_detection, align, expand_percentage, normalization, silent, threshold, anti_spoofing)\u001B[39m\n\u001B[32m    178\u001B[39m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mException while processing img\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mindex\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m_path\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01merr\u001B[39;00m\n\u001B[32m    179\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m img_embeddings, img_facial_areas\n\u001B[32m--> \u001B[39m\u001B[32m181\u001B[39m img1_embeddings, img1_facial_areas = extract_embeddings_and_facial_areas(img1_path, \u001B[32m1\u001B[39m)\n\u001B[32m    182\u001B[39m img2_embeddings, img2_facial_areas = extract_embeddings_and_facial_areas(img2_path, \u001B[32m2\u001B[39m)\n\u001B[32m    184\u001B[39m min_distance, min_idx, min_idy = \u001B[38;5;28mfloat\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33minf\u001B[39m\u001B[33m\"\u001B[39m), \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\fall_detect\\Lib\\site-packages\\deepface\\modules\\verification.py:178\u001B[39m, in \u001B[36mverify.<locals>.extract_embeddings_and_facial_areas\u001B[39m\u001B[34m(img_path, index)\u001B[39m\n\u001B[32m    167\u001B[39m         img_embeddings, img_facial_areas = __extract_faces_and_embeddings(\n\u001B[32m    168\u001B[39m             img_path=img_path,\n\u001B[32m    169\u001B[39m             model_name=model_name,\n\u001B[32m   (...)\u001B[39m\u001B[32m    175\u001B[39m             anti_spoofing=anti_spoofing,\n\u001B[32m    176\u001B[39m         )\n\u001B[32m    177\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[32m--> \u001B[39m\u001B[32m178\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mException while processing img\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mindex\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m_path\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01merr\u001B[39;00m\n\u001B[32m    179\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m img_embeddings, img_facial_areas\n",
      "\u001B[31mValueError\u001B[39m: Exception while processing img1_path"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "a0b8dafa",
   "metadata": {},
   "source": [
    "### Calculate Results\n",
    "\n",
    "Experiments were responsible for calculating distances. We will calculate the best accuracy scores in this block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67376e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[0 for _ in range(len(models))] for _ in range(len(detectors))]\n",
    "base_df = pd.DataFrame(data, columns=models, index=detectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2cc536b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/pivot_euclidean_with_alignment_True.csv saved\n",
      "results/pivot_euclidean_l2_with_alignment_True.csv saved\n",
      "results/pivot_cosine_with_alignment_True.csv saved\n",
      "results/pivot_euclidean_with_alignment_False.csv saved\n",
      "results/pivot_euclidean_l2_with_alignment_False.csv saved\n",
      "results/pivot_cosine_with_alignment_False.csv saved\n"
     ]
    }
   ],
   "source": [
    "for is_aligned in alignment:\n",
    "    for distance_metric in metrics:\n",
    "\n",
    "        current_df = base_df.copy()\n",
    "        \n",
    "        target_file = f\"results/pivot_{distance_metric}_with_alignment.csv\"\n",
    "        if os.path.exists(target_file):\n",
    "            continue\n",
    "        \n",
    "        for model_name in models:\n",
    "            for detector_backend in detectors:\n",
    "\n",
    "                align = \"aligned\" if is_aligned is True else \"unaligned\"\n",
    "\n",
    "                if detector_backend == \"skip\" and is_aligned is True:\n",
    "                    # Alignment is not possible for a skipped detector configuration\n",
    "                    align = \"unaligned\"\n",
    "\n",
    "                source_file = f\"outputs/test/{model_name}_{detector_backend}_{distance_metric}_{align}.csv\"\n",
    "                df = pd.read_csv(source_file)\n",
    "                  \n",
    "                positive_mean = df[(df[\"actuals\"] == True) | (df[\"actuals\"] == 1)][\"distances\"].mean()\n",
    "                negative_mean = df[(df[\"actuals\"] == False) | (df[\"actuals\"] == 0)][\"distances\"].mean()\n",
    "\n",
    "                distances = sorted(df[\"distances\"].values.tolist())\n",
    "\n",
    "                items = []\n",
    "                for i, distance in enumerate(distances):\n",
    "                    if distance >= positive_mean and distance <= negative_mean:\n",
    "                        sandbox_df = df.copy()\n",
    "                        sandbox_df[\"predictions\"] = False\n",
    "                        idx = sandbox_df[sandbox_df[\"distances\"] < distance].index\n",
    "                        sandbox_df.loc[idx, \"predictions\"] = True\n",
    "\n",
    "                        actuals = sandbox_df.actuals.values.tolist()\n",
    "                        predictions = sandbox_df.predictions.values.tolist()\n",
    "                        accuracy = 100*accuracy_score(actuals, predictions)\n",
    "                        items.append((distance, accuracy))\n",
    "\n",
    "                pivot_df = pd.DataFrame(items, columns = [\"distance\", \"accuracy\"])\n",
    "                pivot_df = pivot_df.sort_values(by = [\"accuracy\"], ascending = False)\n",
    "                threshold = pivot_df.iloc[0][\"distance\"]\n",
    "                # print(f\"threshold for {model_name}/{detector_backend} is {threshold}\")\n",
    "                accuracy = pivot_df.iloc[0][\"accuracy\"]\n",
    "\n",
    "                # print(source_file, round(accuracy, 1))\n",
    "                current_df.at[detector_backend, model_name] = round(accuracy, 1)\n",
    "        \n",
    "        current_df.to_csv(target_file)\n",
    "        print(f\"{target_file} saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
