{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-20T21:03:54.237811Z",
     "start_time": "2025-04-20T21:03:44.801513Z"
    }
   },
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import ast"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T21:03:54.266608Z",
     "start_time": "2025-04-20T21:03:54.239500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)"
   ],
   "id": "b1e9acd3edf98f2f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T21:22:39.627107Z",
     "start_time": "2025-04-20T21:22:39.603416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_com(landmarks):\n",
    "    \"\"\"\n",
    "    Calcula el centro de masa (promedio de las posiciones de las articulaciones clave).\n",
    "    Utiliza las caderas y hombros para el cálculo.\n",
    "    \"\"\"\n",
    "    # Puntos clave: Caderas y Hombros\n",
    "    left_hip = np.array([landmarks[mp_pose.PoseLandmark.LEFT_HIP].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.LEFT_HIP].y,\n",
    "                         landmarks[mp_pose.PoseLandmark.LEFT_HIP].z])\n",
    "\n",
    "    right_hip = np.array([landmarks[mp_pose.PoseLandmark.RIGHT_HIP].x,\n",
    "                          landmarks[mp_pose.PoseLandmark.RIGHT_HIP].y,\n",
    "                          landmarks[mp_pose.PoseLandmark.RIGHT_HIP].z])\n",
    "\n",
    "    left_shoulder = np.array([landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].x,\n",
    "                              landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].y,\n",
    "                              landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].z])\n",
    "\n",
    "    right_shoulder = np.array([landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].x,\n",
    "                               landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].y,\n",
    "                               landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].z])\n",
    "\n",
    "    # Calcula el centro de masa como el promedio de los puntos clave\n",
    "    com = (left_hip + right_hip + left_shoulder + right_shoulder) / 4\n",
    "    return com\n",
    "\n",
    "\n",
    "def calculate_torso_orientation(landmarks):\n",
    "    \"\"\"\n",
    "    Calcula la orientación del torso usando los hombros y caderas.\n",
    "    \"\"\"\n",
    "    # Puntos clave: Hombros y Caderas\n",
    "    left_shoulder = np.array([landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].x,\n",
    "                              landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].y,\n",
    "                              landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].z])\n",
    "\n",
    "    right_shoulder = np.array([landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].x,\n",
    "                               landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].y,\n",
    "                               landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].z])\n",
    "\n",
    "    left_hip = np.array([landmarks[mp_pose.PoseLandmark.LEFT_HIP].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.LEFT_HIP].y,\n",
    "                         landmarks[mp_pose.PoseLandmark.LEFT_HIP].z])\n",
    "\n",
    "    right_hip = np.array([landmarks[mp_pose.PoseLandmark.RIGHT_HIP].x,\n",
    "                          landmarks[mp_pose.PoseLandmark.RIGHT_HIP].y,\n",
    "                          landmarks[mp_pose.PoseLandmark.RIGHT_HIP].z])\n",
    "\n",
    "    # Vector hombros (dirección entre los hombros)\n",
    "    shoulder_vector = right_shoulder - left_shoulder\n",
    "\n",
    "    # Centro de las caderas\n",
    "    hip_center = (left_hip + right_hip) / 2\n",
    "\n",
    "    # Vector torso (dirección entre los hombros y el centro de las caderas)\n",
    "    torso_vector = hip_center - (left_shoulder + right_shoulder) / 2\n",
    "\n",
    "    # Producto cruzado para obtener la normal al plano del torso\n",
    "    torso_normal = np.cross(shoulder_vector, torso_vector)\n",
    "\n",
    "    # Normalización del vector normal\n",
    "    torso_normal = torso_normal / np.linalg.norm(torso_normal)\n",
    "\n",
    "    return torso_normal\n",
    "\n",
    "def process_videos(video_directory: str, output_file: str, target: int, frames_per_second: int = 6):\n",
    "    video_data = []  # Para almacenar los datos de todos los videos\n",
    "    video_filenames = [f for f in os.listdir(video_directory) if f.endswith(\".mp4\") or f.endswith(\".avi\")]\n",
    "\n",
    "    for video_filename in tqdm(video_filenames, desc=\"Procesando videos\"):\n",
    "        video_path = os.path.join(video_directory, video_filename)\n",
    "        #print(f\"Procesando video: {video_filename}\")\n",
    "\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        \n",
    "        prev_landmarks = None\n",
    "        prev_velocity = None\n",
    "        video_features = []\n",
    "        video_poses = []\n",
    "        \n",
    "        frame_skip = int(fps // frames_per_second)\n",
    "        frame_count = 0\n",
    "        \n",
    "        while cap.isOpened():\n",
    "            success, image = cap.read()\n",
    "            if not success:\n",
    "                break\n",
    "        \n",
    "            frame_count += 1\n",
    "            if frame_count % frame_skip != 0:\n",
    "                continue  # Saltar este frame\n",
    "            frame_count = 0\n",
    "            \n",
    "            # Procesar la imagen con MediaPipe Pose\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            results = pose.process(image)\n",
    "        \n",
    "            if results.pose_world_landmarks:\n",
    "                landmarks = results.pose_world_landmarks.landmark\n",
    "                joint_index = 0  # Índice del punto a analizar (ej. 0 = Nariz, 23 = Cadera izquierda, etc.)\n",
    "        \n",
    "                if prev_landmarks is not None:\n",
    "                    # Obtener coordenadas actuales y anteriores\n",
    "                    x, y, z = landmarks[joint_index].x, landmarks[joint_index].y, landmarks[joint_index].z\n",
    "                    x_prev, y_prev, z_prev = prev_landmarks[joint_index]\n",
    "        \n",
    "                    # Desplazamiento\n",
    "                    dx, dy, dz = x - x_prev, y - y_prev, z - z_prev\n",
    "                    displacement = np.sqrt(dx**2 + dy**2 + dz**2)\n",
    "        \n",
    "                    # Velocidad (por frame, no por tiempo)\n",
    "                    velocity_x, velocity_y, velocity_z = dx, dy, dz\n",
    "                    velocity = np.sqrt(velocity_x**2 + velocity_y**2 + velocity_z**2)\n",
    "        \n",
    "                    # Aceleración (cambio de velocidad por frame)\n",
    "                    if prev_velocity is not None:\n",
    "                        acceleration_x = velocity_x - prev_velocity[0]\n",
    "                        acceleration_y = velocity_y - prev_velocity[1]\n",
    "                        acceleration_z = velocity_z - prev_velocity[2]\n",
    "                        acceleration = np.sqrt(acceleration_x**2 + acceleration_y**2 + acceleration_z**2)\n",
    "                    else:\n",
    "                        acceleration_x, acceleration_y, acceleration_z, acceleration = 0, 0, 0, 0\n",
    "        \n",
    "                    tangent_angle = np.arctan2(dy, dx) * (180 / np.pi)\n",
    "                    com = calculate_com(landmarks)\n",
    "                    com_x, com_y, com_z = com\n",
    "                    torso_normal = calculate_torso_orientation(landmarks)\n",
    "        \n",
    "                    frame_features = {\n",
    "                        \"displacement\": displacement,\n",
    "                        \"velocity\": velocity,\n",
    "                        \"acceleration\": acceleration,\n",
    "                        \"tangent_angle\": tangent_angle,\n",
    "                        \"com\": (com_x, com_y, com_z),\n",
    "                        \"torso_normal\": torso_normal\n",
    "                    }\n",
    "                    video_features.append(frame_features)\n",
    "                    prev_velocity = (velocity_x, velocity_y, velocity_z)\n",
    "                \n",
    "                else:\n",
    "                    frame_features = {\n",
    "                        \"displacement\": 0.0,\n",
    "                        \"velocity\": 0.0,\n",
    "                        \"acceleration\": 0.0,\n",
    "                        \"tangent_angle\": 0.0,\n",
    "                        \"com\": (0.0, 0.0, 0.0),\n",
    "                        \"torso_normal\": [0.0, 0.0, 0.0]\n",
    "                    }\n",
    "                    video_features.append(frame_features)\n",
    "                prev_landmarks = [(lm.x, lm.y, lm.z) for lm in landmarks]\n",
    "                video_poses.append(prev_landmarks)\n",
    "            \n",
    "        cap.release()\n",
    "\n",
    "        video_data.append({\n",
    "            \"video_filename\": video_filename,\n",
    "            \"features\": video_features,\n",
    "            \"poses\": video_poses,\n",
    "            \"target\": target\n",
    "        })\n",
    "\n",
    "    df_rows = []\n",
    "\n",
    "    for video in video_data:\n",
    "        filename = video[\"video_filename\"]\n",
    "        features = video[\"features\"]\n",
    "        poses = video[\"poses\"]\n",
    "        target = video[\"target\"]\n",
    "    \n",
    "        # Convertir cada frame de poses a un solo vector [x1, y1, z1, ..., xN, yN, zN]\n",
    "        poses_sec = []\n",
    "        for pose_un in poses:\n",
    "            flat_pose = []\n",
    "            for x, y, z in pose_un:\n",
    "                flat_pose.extend([x, y, z])\n",
    "            poses_sec.append(flat_pose)\n",
    "    \n",
    "        # Opcional: convertir cada diccionario de features a un vector ordenado\n",
    "        features_sec = []\n",
    "        for feat in features:\n",
    "            features_sec.append([\n",
    "                feat[\"displacement\"],\n",
    "                feat[\"velocity\"],\n",
    "                feat[\"acceleration\"],\n",
    "                feat[\"tangent_angle\"],\n",
    "                feat[\"com\"][0], feat[\"com\"][1], feat[\"com\"][2],\n",
    "                feat[\"torso_normal\"][0], feat[\"torso_normal\"][1], feat[\"torso_normal\"][2]\n",
    "            ])\n",
    "    \n",
    "        df_rows.append({\n",
    "            \"video_filename\": filename,\n",
    "            \"poses_sec\": poses_sec,\n",
    "            \"features\": features_sec,\n",
    "            \"target\": target\n",
    "        })\n",
    "    \n",
    "    # Crear el DataFrame\n",
    "    df = pd.DataFrame(df_rows)\n",
    "    \n",
    "    # Guardar como CSV\n",
    "    df.to_csv(f\"{output_file}.csv\", index=False)\n",
    "    \n",
    "    print(f\"Datos guardados en {output_file}.csv\")"
   ],
   "id": "80f7d6e14009abc6",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T21:29:26.127698Z",
     "start_time": "2025-04-20T21:22:41.890296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "process_videos(video_directory=\"C:/Users/bryan/OneDrive/Documentos/Tesis/fall_detection/data/GMDCSA24/Fall\", output_file=\"fall\", target=1)\n",
    "\n",
    "process_videos(video_directory=\"C:/Users/bryan/OneDrive/Documentos/Tesis/fall_detection/data/GMDCSA24/ADL\", output_file=\"adl\", target=0)"
   ],
   "id": "fd71c1ed2ed619fe",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando videos: 100%|██████████| 67/67 [02:44<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos guardados en fall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando videos: 100%|██████████| 81/81 [03:59<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos guardados en adl\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T21:17:12.507507Z",
     "start_time": "2025-04-20T21:17:12.500779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def unir_csvs(ruta_csv1, ruta_csv2, ruta_salida):\n",
    "    # Leer los CSV\n",
    "    df1 = pd.read_csv(ruta_csv1)\n",
    "    df2 = pd.read_csv(ruta_csv2)\n",
    "\n",
    "    # Verificar que tienen las mismas columnas\n",
    "    if list(df1.columns) != list(df2.columns):\n",
    "        raise ValueError(\"Los archivos CSV no tienen las mismas columnas.\")\n",
    "\n",
    "    # Unir los DataFrames\n",
    "    df_combinado = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "    # Guardar el resultado\n",
    "    df_combinado.to_csv(ruta_salida, index=False)\n",
    "    print(f\"Archivo combinado guardado en: {ruta_salida}\")"
   ],
   "id": "652ddfb3e5f379f6",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T21:17:14.571947Z",
     "start_time": "2025-04-20T21:17:14.563533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_csv(file:str, outfile:str):\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    # Convertir las cadenas a listas reales usando ast.literal_eval\n",
    "    df[\"poses_sec\"] = df[\"poses_sec\"].apply(ast.literal_eval)\n",
    "    df[\"features\"] = df[\"features\"].apply(ast.literal_eval)\n",
    "    \n",
    "    # Obtener la longitud máxima de poses y features\n",
    "    max_len_poses = max(len(seq) for seq in df[\"poses_sec\"])\n",
    "    max_len_features = max(len(seq) for seq in df[\"features\"])\n",
    "    \n",
    "    # Aplicar padding a cada fila\n",
    "    for idx, row in df.iterrows():\n",
    "        #print(f\"Video {idx}: poses_len={len(row['poses_sec'])}, features_len={len(row['features'])}\")\n",
    "        poses_seq = row[\"poses_sec\"]\n",
    "        features_seq = row[\"features\"]\n",
    "    \n",
    "        # Padding de poses\n",
    "        if len(poses_seq) < max_len_poses:\n",
    "            num_pose_dims = len(poses_seq[0]) if poses_seq else 99  # 33 puntos x 3 coords\n",
    "            padding_poses = [[0.0] * num_pose_dims] * (max_len_poses - len(poses_seq))\n",
    "            poses_seq.extend(padding_poses)\n",
    "    \n",
    "        # Padding de features\n",
    "        if len(features_seq) < max_len_features:\n",
    "            num_feat_dims = len(features_seq[0]) if features_seq else 10  # 10 características\n",
    "            padding_feats = [[0.0] * num_feat_dims] * (max_len_features - len(features_seq))\n",
    "            features_seq.extend(padding_feats)\n",
    "    \n",
    "        # Guardar las secuencias de nuevo en el DataFrame\n",
    "        df.at[idx, \"poses_sec\"] = poses_seq\n",
    "        df.at[idx, \"features\"] = features_seq\n",
    "    \n",
    "    # Guardar el nuevo DataFrame\n",
    "    df.to_csv(outfile, index=False)\n",
    "    \n",
    "    print(\"✅ Secuencias normalizadas y guardadas.\")"
   ],
   "id": "550f9180a03290c1",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T21:17:17.169197Z",
     "start_time": "2025-04-20T21:17:17.160630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def verify_csv(file:str):\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    df[\"poses_sec\"] = df[\"poses_sec\"].apply(ast.literal_eval)\n",
    "    df[\"features\"] = df[\"features\"].apply(ast.literal_eval)\n",
    "    \n",
    "    # Revisar la longitud de cada secuencia\n",
    "    lengths_poses = df[\"poses_sec\"].apply(len)\n",
    "    lengths_features = df[\"features\"].apply(len)\n",
    "    \n",
    "    # Verificar si todas tienen la misma longitud\n",
    "    consistent_poses = lengths_poses.nunique() == 1\n",
    "    consistent_features = lengths_features.nunique() == 1\n",
    "    \n",
    "    print(\"✅ Verificación de secuencias:\")\n",
    "    print(f\"- Todas las secuencias de 'poses_sec' tienen la misma longitud: {consistent_poses}\")\n",
    "    print(f\"- Todas las secuencias de 'features' tienen la misma longitud: {consistent_features}\")\n",
    "    print(f\"  Longitud común de poses_sec: {lengths_poses.iloc[0]}\")\n",
    "    print(f\"  Longitud común de features: {lengths_features.iloc[0]}\")"
   ],
   "id": "e6312a7ddbddb0c5",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T21:31:01.933644Z",
     "start_time": "2025-04-20T21:30:47.268754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "unir_csvs(\"adl.csv\", \"fall.csv\", \"combined.csv\")\n",
    "clean_csv(\"combined.csv\", \"combined_padded.csv\")\n",
    "verify_csv(\"combined_padded.csv\")"
   ],
   "id": "62334a687b3749c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo combinado guardado en: combined.csv\n",
      "Video 0: poses_len=60, features_len=60\n",
      "Video 1: poses_len=48, features_len=48\n",
      "Video 2: poses_len=49, features_len=49\n",
      "Video 3: poses_len=73, features_len=73\n",
      "Video 4: poses_len=80, features_len=80\n",
      "Video 5: poses_len=59, features_len=59\n",
      "Video 6: poses_len=63, features_len=63\n",
      "Video 7: poses_len=56, features_len=56\n",
      "Video 8: poses_len=76, features_len=76\n",
      "Video 9: poses_len=90, features_len=90\n",
      "Video 10: poses_len=81, features_len=81\n",
      "Video 11: poses_len=43, features_len=43\n",
      "Video 12: poses_len=70, features_len=70\n",
      "Video 13: poses_len=76, features_len=76\n",
      "Video 14: poses_len=75, features_len=75\n",
      "Video 15: poses_len=70, features_len=70\n",
      "Video 16: poses_len=65, features_len=65\n",
      "Video 17: poses_len=67, features_len=67\n",
      "Video 18: poses_len=38, features_len=38\n",
      "Video 19: poses_len=65, features_len=65\n",
      "Video 20: poses_len=24, features_len=24\n",
      "Video 21: poses_len=36, features_len=36\n",
      "Video 22: poses_len=58, features_len=58\n",
      "Video 23: poses_len=92, features_len=92\n",
      "Video 24: poses_len=89, features_len=89\n",
      "Video 25: poses_len=41, features_len=41\n",
      "Video 26: poses_len=66, features_len=66\n",
      "Video 27: poses_len=91, features_len=91\n",
      "Video 28: poses_len=55, features_len=55\n",
      "Video 29: poses_len=46, features_len=46\n",
      "Video 30: poses_len=36, features_len=36\n",
      "Video 31: poses_len=27, features_len=27\n",
      "Video 32: poses_len=68, features_len=68\n",
      "Video 33: poses_len=54, features_len=54\n",
      "Video 34: poses_len=46, features_len=46\n",
      "Video 35: poses_len=43, features_len=43\n",
      "Video 36: poses_len=53, features_len=53\n",
      "Video 37: poses_len=26, features_len=26\n",
      "Video 38: poses_len=41, features_len=41\n",
      "Video 39: poses_len=49, features_len=49\n",
      "Video 40: poses_len=34, features_len=34\n",
      "Video 41: poses_len=92, features_len=92\n",
      "Video 42: poses_len=90, features_len=90\n",
      "Video 43: poses_len=91, features_len=91\n",
      "Video 44: poses_len=79, features_len=79\n",
      "Video 45: poses_len=64, features_len=64\n",
      "Video 46: poses_len=41, features_len=41\n",
      "Video 47: poses_len=62, features_len=62\n",
      "Video 48: poses_len=39, features_len=39\n",
      "Video 49: poses_len=104, features_len=104\n",
      "Video 50: poses_len=53, features_len=53\n",
      "Video 51: poses_len=73, features_len=73\n",
      "Video 52: poses_len=130, features_len=130\n",
      "Video 53: poses_len=92, features_len=92\n",
      "Video 54: poses_len=78, features_len=78\n",
      "Video 55: poses_len=66, features_len=66\n",
      "Video 56: poses_len=97, features_len=97\n",
      "Video 57: poses_len=47, features_len=47\n",
      "Video 58: poses_len=79, features_len=79\n",
      "Video 59: poses_len=80, features_len=80\n",
      "Video 60: poses_len=80, features_len=80\n",
      "Video 61: poses_len=96, features_len=96\n",
      "Video 62: poses_len=102, features_len=102\n",
      "Video 63: poses_len=81, features_len=81\n",
      "Video 64: poses_len=56, features_len=56\n",
      "Video 65: poses_len=74, features_len=74\n",
      "Video 66: poses_len=55, features_len=55\n",
      "Video 67: poses_len=35, features_len=35\n",
      "Video 68: poses_len=63, features_len=63\n",
      "Video 69: poses_len=81, features_len=81\n",
      "Video 70: poses_len=85, features_len=85\n",
      "Video 71: poses_len=78, features_len=78\n",
      "Video 72: poses_len=84, features_len=84\n",
      "Video 73: poses_len=87, features_len=87\n",
      "Video 74: poses_len=77, features_len=77\n",
      "Video 75: poses_len=90, features_len=90\n",
      "Video 76: poses_len=54, features_len=54\n",
      "Video 77: poses_len=85, features_len=85\n",
      "Video 78: poses_len=88, features_len=88\n",
      "Video 79: poses_len=87, features_len=87\n",
      "Video 80: poses_len=57, features_len=57\n",
      "Video 81: poses_len=30, features_len=30\n",
      "Video 82: poses_len=20, features_len=20\n",
      "Video 83: poses_len=44, features_len=44\n",
      "Video 84: poses_len=43, features_len=43\n",
      "Video 85: poses_len=27, features_len=27\n",
      "Video 86: poses_len=36, features_len=36\n",
      "Video 87: poses_len=30, features_len=30\n",
      "Video 88: poses_len=35, features_len=35\n",
      "Video 89: poses_len=42, features_len=42\n",
      "Video 90: poses_len=50, features_len=50\n",
      "Video 91: poses_len=33, features_len=33\n",
      "Video 92: poses_len=22, features_len=22\n",
      "Video 93: poses_len=26, features_len=26\n",
      "Video 94: poses_len=54, features_len=54\n",
      "Video 95: poses_len=44, features_len=44\n",
      "Video 96: poses_len=46, features_len=46\n",
      "Video 97: poses_len=25, features_len=25\n",
      "Video 98: poses_len=44, features_len=44\n",
      "Video 99: poses_len=24, features_len=24\n",
      "Video 100: poses_len=32, features_len=32\n",
      "Video 101: poses_len=35, features_len=35\n",
      "Video 102: poses_len=42, features_len=42\n",
      "Video 103: poses_len=41, features_len=41\n",
      "Video 104: poses_len=37, features_len=37\n",
      "Video 105: poses_len=31, features_len=31\n",
      "Video 106: poses_len=26, features_len=26\n",
      "Video 107: poses_len=32, features_len=32\n",
      "Video 108: poses_len=44, features_len=44\n",
      "Video 109: poses_len=49, features_len=49\n",
      "Video 110: poses_len=31, features_len=31\n",
      "Video 111: poses_len=41, features_len=41\n",
      "Video 112: poses_len=44, features_len=44\n",
      "Video 113: poses_len=44, features_len=44\n",
      "Video 114: poses_len=46, features_len=46\n",
      "Video 115: poses_len=84, features_len=84\n",
      "Video 116: poses_len=114, features_len=114\n",
      "Video 117: poses_len=113, features_len=113\n",
      "Video 118: poses_len=51, features_len=51\n",
      "Video 119: poses_len=74, features_len=74\n",
      "Video 120: poses_len=32, features_len=32\n",
      "Video 121: poses_len=47, features_len=47\n",
      "Video 122: poses_len=32, features_len=32\n",
      "Video 123: poses_len=43, features_len=43\n",
      "Video 124: poses_len=33, features_len=33\n",
      "Video 125: poses_len=35, features_len=35\n",
      "Video 126: poses_len=73, features_len=73\n",
      "Video 127: poses_len=88, features_len=88\n",
      "Video 128: poses_len=84, features_len=84\n",
      "Video 129: poses_len=63, features_len=63\n",
      "Video 130: poses_len=76, features_len=76\n",
      "Video 131: poses_len=85, features_len=85\n",
      "Video 132: poses_len=28, features_len=28\n",
      "Video 133: poses_len=46, features_len=46\n",
      "Video 134: poses_len=84, features_len=84\n",
      "Video 135: poses_len=61, features_len=61\n",
      "Video 136: poses_len=36, features_len=36\n",
      "Video 137: poses_len=54, features_len=54\n",
      "Video 138: poses_len=52, features_len=52\n",
      "Video 139: poses_len=53, features_len=53\n",
      "Video 140: poses_len=46, features_len=46\n",
      "Video 141: poses_len=41, features_len=41\n",
      "Video 142: poses_len=85, features_len=85\n",
      "Video 143: poses_len=60, features_len=60\n",
      "Video 144: poses_len=36, features_len=36\n",
      "Video 145: poses_len=54, features_len=54\n",
      "Video 146: poses_len=52, features_len=52\n",
      "Video 147: poses_len=53, features_len=53\n",
      "✅ Secuencias normalizadas y guardadas.\n",
      "✅ Verificación de secuencias:\n",
      "- Todas las secuencias de 'poses_sec' tienen la misma longitud: True\n",
      "- Todas las secuencias de 'features' tienen la misma longitud: True\n",
      "  Longitud común de poses_sec: 130\n",
      "  Longitud común de features: 130\n"
     ]
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
