{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!pip install git+https://github.com/serengil/deepface.git\n",
    "!pip install ultralytics --no-deps"
   ],
   "id": "d2805a7d6cb5de73"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T20:37:17.322087Z",
     "start_time": "2025-05-25T20:37:07.943956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from deepface import DeepFace\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from sklearn.metrics import accuracy_score\n",
    "import csv\n",
    "import time\n",
    "from PIL import Image"
   ],
   "id": "ac5b5f0307a4d48",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\bryan\\anaconda3\\envs\\yolo_fall_detect\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "INPUT_PATH = \"/kaggle/input/dataset/merged_lfw_cplfw_50\"\n",
    "SIZES = [250,100, 50, 25]\n",
    "OUTPUT_BASE = \"/kaggle/working/\"\n",
    "SPLIT_SIZE = 10"
   ],
   "id": "97603967fd40aafd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def resize_and_save_all(input_path, output_base, sizes):\n",
    "    for size in sizes:\n",
    "        output_path = os.path.join(output_base, f\"merged_lfw_cplfw_50_{size}\")\n",
    "        if not os.path.exists(output_path):\n",
    "            os.makedirs(output_path)\n",
    "        for subj in os.listdir(input_path):\n",
    "            subj_in = os.path.join(input_path, subj)\n",
    "            subj_out = os.path.join(output_path, subj)\n",
    "            if os.path.isdir(subj_in):\n",
    "                os.makedirs(subj_out, exist_ok=True)\n",
    "                for img_name in os.listdir(subj_in):\n",
    "                    in_img_path = os.path.join(subj_in, img_name)\n",
    "                    out_img_path = os.path.join(subj_out, img_name)\n",
    "                    try:\n",
    "                        with Image.open(in_img_path) as img:\n",
    "                            img = img.convert(\"RGB\")\n",
    "                            img = img.resize((size, size), Image.LANCZOS)\n",
    "                            img.save(out_img_path)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error con {in_img_path}: {e}\")"
   ],
   "id": "d2a47a9ed81790d9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "resize_and_save_all(INPUT_PATH, OUTPUT_BASE, SIZES)\n",
    "print(\"Redimensionado terminado.\")"
   ],
   "id": "92d54f3b4784adee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_all_images(dataset_path):\n",
    "    images = []\n",
    "    for subj in os.listdir(dataset_path):\n",
    "        subj_path = os.path.join(dataset_path, subj)\n",
    "        if os.path.isdir(subj_path):\n",
    "            for img in os.listdir(subj_path):\n",
    "                if img.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    images.append((subj, os.path.join(subj_path, img)))\n",
    "    return images\n",
    "\n",
    "def extract_embeddings(images, model, detector, emb_path, csv_writer):\n",
    "    save_dir = os.path.join(emb_path, model, detector)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    total_time = 0\n",
    "    count = 0\n",
    "    for subj, img_path in images:\n",
    "        subj_dir = os.path.join(save_dir, subj)\n",
    "        os.makedirs(subj_dir, exist_ok=True)\n",
    "        emb_file = os.path.join(subj_dir, os.path.basename(img_path) + \".npy\")\n",
    "        if not os.path.exists(emb_file):\n",
    "            try:\n",
    "                start_time = time.time()\n",
    "                emb = DeepFace.represent(\n",
    "                    img_path=img_path,\n",
    "                    model_name=model,\n",
    "                    detector_backend=detector,\n",
    "                    enforce_detection=True,\n",
    "                    align=True\n",
    "                )[0][\"embedding\"]\n",
    "                elapsed = time.time() - start_time\n",
    "                total_time += elapsed\n",
    "                count += 1\n",
    "                np.save(emb_file, emb)\n",
    "                print(f\"{model} | {detector} | {img_path} | Tiempo: {elapsed:.3f} seg\")\n",
    "                # Guardar en el CSV\n",
    "                csv_writer.writerow([model, detector, subj, img_path, elapsed])\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {img_path} | {e}\")\n",
    "    if count > 0:\n",
    "        avg_time = total_time / count\n",
    "        print(f\"\\nModelo: {model} | Detector: {detector} | Tiempo total: {total_time:.2f} seg | Imágenes procesadas: {count} | Tiempo promedio: {avg_time:.3f} seg\")\n",
    "    else:\n",
    "        print(f\"\\nModelo: {model} | Detector: {detector} | No se procesaron imágenes.\")"
   ],
   "id": "f5feb25deca77f7d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def load_embeddings(model, detector):\n",
    "    emb_dir = os.path.join(EMB_PATH, model, detector)\n",
    "    subjects = {}\n",
    "    for subj in os.listdir(emb_dir):\n",
    "        subj_path = os.path.join(emb_dir, subj)\n",
    "        if os.path.isdir(subj_path):\n",
    "            lfw_embs = []\n",
    "            cplfw_embs = []\n",
    "            for emb_name in os.listdir(subj_path):\n",
    "                emb_path = os.path.join(subj_path, emb_name)\n",
    "                emb = np.load(emb_path)\n",
    "                if emb_name.startswith(\"lfw_\"):\n",
    "                    lfw_embs.append((emb_name, emb))\n",
    "                elif emb_name.startswith(\"cplfw_\"):\n",
    "                    cplfw_embs.append((emb_name, emb))\n",
    "            if len(lfw_embs) == 10 and len(cplfw_embs) > 0:\n",
    "                subjects[subj] = {\"lfw\": lfw_embs, \"cplfw\": cplfw_embs}\n",
    "    return subjects\n",
    "\n",
    "def split_subjects(subjects, split_size):\n",
    "    subject_list = sorted(list(subjects.keys()))\n",
    "    return [subject_list[i:i+split_size] for i in range(0, len(subject_list), split_size)]\n",
    "\n",
    "def benchmark_block(subjects, block_subjects):\n",
    "    references = {subj: [emb for name, emb in subjects[subj][\"lfw\"]] for subj in block_subjects}\n",
    "    probes = []\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    # Prepara pruebas (todas las cplfw)\n",
    "    for subj in block_subjects:\n",
    "        for probe_name, probe_emb in subjects[subj][\"cplfw\"]:\n",
    "            probes.append((probe_emb, subj))\n",
    "            true_labels.append(subj)\n",
    "    # Comparación solo de embeddings (coseno)\n",
    "    for probe_emb, true_subj in probes:\n",
    "        min_dist = float(\"inf\")\n",
    "        best_match = None\n",
    "        for ref_subj, ref_embs in references.items():\n",
    "            dists = cosine_distances([probe_emb], ref_embs)[0]\n",
    "            dist = np.min(dists)\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                best_match = ref_subj\n",
    "        pred_labels.append(best_match)\n",
    "    acc = accuracy_score(true_labels, pred_labels)\n",
    "    return acc, len(probes)"
   ],
   "id": "c3a2b619aa7ab4ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "BASE_INPUT = \"/kaggle/working\"\n",
    "BASE_EMB = \"/kaggle/working\"\n",
    "MODELS = [\"Facenet\", \"VGG-Face\", \"ArcFace\", \"GhostFaceNet\", \"OpenFace\"]\n",
    "DETECTORS = [\"retinaface\", \"centerface\", \"yunet\", \"yolov8\",\"yolov11s\", \"yolov11n\"]\n",
    "SPLIT_SIZE = 10\n",
    "\n",
    "for size in SIZES:\n",
    "    print(f\"-----------------INICIANDO SIZE {size}-----------------\")\n",
    "    DATASET_PATH = f\"{BASE_INPUT}/merged_lfw_cplfw_50_{size}\"\n",
    "    EMB_PATH = f\"{BASE_EMB}/embeddings_{size}\"\n",
    "    os.makedirs(EMB_PATH, exist_ok=True)\n",
    "    CSV_BENCHMARK = os.path.join(EMB_PATH, f\"benchmark_results_{size}.csv\")\n",
    "    csv_file = os.path.join(EMB_PATH, f\"embedding_times_{size}.csv\")\n",
    "\n",
    "    images = get_all_images(DATASET_PATH)\n",
    "    header = [\"model\", \"detector\", \"subject\", \"image_path\", \"embedding_time_sec\"]\n",
    "    with open(csv_file, mode=\"w\", newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(header)\n",
    "        for model in MODELS:\n",
    "            for detector in DETECTORS:\n",
    "                print(f\"Extrayendo embeddings para modelo: {model} | detector: {detector} | size: {size}\")\n",
    "                extract_embeddings(images, model, detector, EMB_PATH, writer)\n",
    "    print(f\"¡Embeddings extraídos y tiempos guardados en {csv_file}!\")\n",
    "\n",
    "    with open(CSV_BENCHMARK, \"w\", newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"model\", \"detector\", \"split\", \"accuracy\", \"n_samples\"])\n",
    "        for model in MODELS:\n",
    "            for detector in DETECTORS:\n",
    "                print(f\"Benchmarking modelo: {model} | detector: {detector} | size: {size}\")\n",
    "                subjects = load_embeddings(model, detector)\n",
    "                splits = split_subjects(subjects, SPLIT_SIZE)\n",
    "                for i, block_subjects in enumerate(splits):\n",
    "                    acc, n = benchmark_block(subjects, block_subjects)\n",
    "                    print(f\"Split {i+1}: Acc: {acc:.3f} (n={n})\")\n",
    "                    writer.writerow([model, detector, i+1, acc, n])\n",
    "    print(f\"Resultados del benchmark guardados en: {CSV_BENCHMARK}\")"
   ],
   "id": "99082c076d41811a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
