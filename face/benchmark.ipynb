{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install deepface",
   "id": "d2805a7d6cb5de73"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T20:37:17.322087Z",
     "start_time": "2025-05-25T20:37:07.943956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from deepface import DeepFace\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "id": "ac5b5f0307a4d48",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\bryan\\anaconda3\\envs\\yolo_fall_detect\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = \"dataset/merged_lfw_cplfw\"\n",
    "EMB_PATH = \"dataset/embeddings\"\n",
    "MODELS = [\"Facenet\", \"VGG-Face\", \"ArcFace\", \"GhostFaceNet\", \"OpenFace\"]\n",
    "DETECTORS = [\"retinaface\", \"centerface\", \"yunet\", \"yolov8\"]\n",
    "\n",
    "def get_all_images(dataset_path):\n",
    "    images = []\n",
    "    for subj in os.listdir(dataset_path):\n",
    "        subj_path = os.path.join(dataset_path, subj)\n",
    "        if os.path.isdir(subj_path):\n",
    "            for img in os.listdir(subj_path):\n",
    "                if img.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    images.append((subj, os.path.join(subj_path, img)))\n",
    "    return images\n",
    "\n",
    "def extract_embeddings(images, model, detector, emb_path):\n",
    "    save_dir = os.path.join(emb_path, model, detector)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    for subj, img_path in images:\n",
    "        subj_dir = os.path.join(save_dir, subj)\n",
    "        os.makedirs(subj_dir, exist_ok=True)\n",
    "        emb_file = os.path.join(subj_dir, os.path.basename(img_path) + \".npy\")\n",
    "        if not os.path.exists(emb_file):  # Skip si ya existe\n",
    "            try:\n",
    "                emb = DeepFace.represent(img_path=img_path, model_name=model, detector_backend=detector, enforce_detection=(detector != \"skip\"), align=True)[0][\"embedding\"]\n",
    "                np.save(emb_file, emb)\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {img_path} | {e}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "images = get_all_images(DATASET_PATH)\n",
    "for model in MODELS:\n",
    "    for detector in DETECTORS:\n",
    "        print(f\"Extrayendo embeddings para modelo: {model} | detector: {detector}\")\n",
    "        extract_embeddings(images, model, detector, EMB_PATH)\n",
    "print(\"¡Embeddings extraídos y guardados!\")"
   ],
   "id": "47b1e61cab5676f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "SPLIT_SIZE = 10\n",
    "\n",
    "def load_embeddings(model, detector):\n",
    "    emb_dir = os.path.join(EMB_PATH, model, detector)\n",
    "    subjects = {}\n",
    "    for subj in os.listdir(emb_dir):\n",
    "        subj_path = os.path.join(emb_dir, subj)\n",
    "        if os.path.isdir(subj_path):\n",
    "            lfw_embs = []\n",
    "            cplfw_embs = []\n",
    "            for emb_name in os.listdir(subj_path):\n",
    "                emb_path = os.path.join(subj_path, emb_name)\n",
    "                emb = np.load(emb_path)\n",
    "                if emb_name.startswith(\"lfw_\"):\n",
    "                    lfw_embs.append((emb_name, emb))\n",
    "                elif emb_name.startswith(\"cplfw_\"):\n",
    "                    cplfw_embs.append((emb_name, emb))\n",
    "            if len(lfw_embs) == 10 and len(cplfw_embs) > 0:\n",
    "                subjects[subj] = {\"lfw\": lfw_embs, \"cplfw\": cplfw_embs}\n",
    "    return subjects\n",
    "\n",
    "def split_subjects(subjects, split_size):\n",
    "    subject_list = sorted(list(subjects.keys()))\n",
    "    return [subject_list[i:i+split_size] for i in range(0, len(subject_list), split_size)]\n",
    "\n",
    "def benchmark_block(subjects, block_subjects):\n",
    "    references = {subj: [emb for name, emb in subjects[subj][\"lfw\"]] for subj in block_subjects}\n",
    "    probes = []\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    # Prepara pruebas (todas las cplfw)\n",
    "    for subj in block_subjects:\n",
    "        for probe_name, probe_emb in subjects[subj][\"cplfw\"]:\n",
    "            probes.append((probe_emb, subj))\n",
    "            true_labels.append(subj)\n",
    "    # Comparación solo de embeddings (coseno)\n",
    "    for probe_emb, true_subj in probes:\n",
    "        min_dist = float(\"inf\")\n",
    "        best_match = None\n",
    "        for ref_subj, ref_embs in references.items():\n",
    "            dists = cosine_distances([probe_emb], ref_embs)[0]\n",
    "            dist = np.min(dists)\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                best_match = ref_subj\n",
    "        pred_labels.append(best_match)\n",
    "    acc = accuracy_score(true_labels, pred_labels)\n",
    "    return acc, len(probes)"
   ],
   "id": "9f48b9fb755ffcbc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for model in MODELS:\n",
    "    for detector in DETECTORS:\n",
    "        print(f\"Benchmarking modelo: {model} | detector: {detector}\")\n",
    "        subjects = load_embeddings(model, detector)\n",
    "        splits = split_subjects(subjects, SPLIT_SIZE)\n",
    "        for i, block_subjects in enumerate(splits):\n",
    "            acc, n = benchmark_block(subjects, block_subjects)\n",
    "            print(f\"Split {i+1}: Acc: {acc:.3f} (n={n})\")"
   ],
   "id": "b1fbcb46408e1a5b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
